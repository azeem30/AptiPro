D a t a S t r u c t u r e s a n d A l g o r i t h m s DSA Annotated Reference with Examples Granville Barne Luca Del TongoData Structures and Algorithms Annotated Reference with Examples First Edition Copyright cid176c Granville Barnett and Luca Del Tongo 2008This book is made exclusively available from DotNetSlackers httpdotnetslackerscom the place for NET articles and news from some of the leading minds in the software industryContents 1 Introduction 1 11 What this book is and what it isnt 1 12 Assumed knowledge 1 121 Big Oh notation 1 122 Imperative programming language 3 123 Object oriented concepts 4 13 Pseudocode 4 14 Tips for working through the examples 6 15 Book outline 6 16 Testing 7 17 Where can I get the code 7 18 Final messages 7 I Data Structures 8 2 Linked Lists 9 21 Singly Linked List 9 211 Insertion 10 212 Searching 10 213 Deletion 11 214 Traversing the list 12 215 Traversing the list in reverse order 13 22 Doubly Linked List 13 221 Insertion 15 222 Deletion 15 223 Reverse Traversal 16 23 Summary 17 3 Binary Search Tree 19 31 Insertion 20 32 Searching 21 33 Deletion 22 34 Finding the parent of a given node 24 35 Attaining a reference to a node 24 36 Finding the smallest and largest values in the binary search tree 25 37 Tree Traversals 26 371 Preorder 26 I372 Postorder 26 373 Inorder 29 374 Breadth First 30 38 Summary 31 4 Heap 32 41 Insertion 33 42 Deletion 37 43 Searching 38 44 Traversal 41 45 Summary 42 5 Sets 44 51 Unordered 46 511 Insertion 46 52 Ordered 47 53 Summary 47 6 Queues 48 61 A standard queue 49 62 Priority Queue 49 63 Double Ended Queue 49 64 Summary 53 7 AVL Tree 54 71 Tree Rotations 56 72 Tree Rebalancing 57 73 Insertion 58 74 Deletion 59 75 Summary 61 II Algorithms 62 8 Sorting 63 81 Bubble Sort 63 82 Merge Sort 63 83 Quick Sort 65 84 Insertion Sort 67 85 Shell Sort 68 86 Radix Sort 68 87 Summary 70 9 Numeric 72 91 Primality Test 72 92 Base conversions 72 93 Attaining the greatest common denominator of two numbers 73 94 Computing the maximum value for a number of a specific base consisting of N digits 74 95 Factorial of a number 74 96 Summary 75 II10 Searching 76 101 Sequential Search 76 102 Probability Search 76 103 Summary 77 11 Strings 79 111 Reversing the order of words in a sentence 79 112 Detecting a palindrome 80 113 Counting the number of words in a string 81 114 Determining the number of repeated words within a string 83 115 Determining the first matching character between two strings 84 116 Summary 85 A Algorithm Walkthrough 86 A1 Iterative algorithms 86 A2 Recursive Algorithms 88 A3 Summary 90 B Translation Walkthrough 91 B1 Summary 92 C Recursive Vs Iterative Solutions 93 C1 Activation Records 94 C2 Some problems are recursive in nature 95 C3 Summary 95 D Testing 97 D1 What constitutes a unit test 97 D2 When should I write my tests 98 D3 How seriously should I view my test suite 99 D4 The three As 99 D5 The structuring of tests 99 D6 Code Coverage 100 D7 Summary 100 E Symbol Definitions 101 IIIPreface Every book has a story as to how it came about and this one is no different although we would be lying if we said its development had not been somewhat impromptu Put simply this book is the result of a series of emails sent back and forth between the two authors during the development of a library for the NET framework of the same name with the omission of the subtitle of course The conversation started off something like Why dont we create a more aesthetically pleasing way to present our pseudocode After a few weeks this new presentation style had in fact grown into pseudocode listings with chunks of text describing how the data structure or algorithm in question works and various other things about it At this point we thought What the heck lets make this thing into a book And so in the summer of 2008 we began work on this book side by side with the actual library implementation When we started writing this book the only things that we were sure about with respect to how the book should be structured were 1 alwaysmakeexplanationsassimpleaspossiblewhilemaintainingamoder atelyfinedegreeofprecisiontokeepthemoreeagermindedreaderhappy and 2 injectdiagramstodemystifyproblemsthatareevenmoderatlychallenging tovisualiseandsowecouldrememberhowourownalgorithmsworked when looking back at them and finally 3 presentconciseandselfexplanatorypseudocodelistingsthatcanbeported easily to most mainstream imperative programming languages like C C and Java A key factor of this book and its associated implementations is that all algorithms unless otherwise stated were designed by us using the theory of the algorithm in question as a guideline for which we are eternally grateful to their original creators Therefore they may sometimes turn out to be worse than the normal implementationsand sometimes not We are two fellows of the opinion that choice is a great thing Read our book read several others on the same subject and use what you see fit from each if anything when implementing your own version of the algorithms in question Throughthisbookwehopethatyouwillseetheabsolutenecessityofunder standing which data structure or algorithm to use for a certain scenario In all projects especially those that are concerned with performance here we apply an even greater emphasis on realtime systems the selection of the wrong data structure or algorithm can be the cause of a great deal of performance pain IVV Thereforeitisabsolutelykeythatyouthinkabouttheruntimecomplexityand space requirements of your selected approach In this book we only explain the theoreticalimplications to consider but this is fora good reason compilers are very different in how they work One C compiler may have some amazing optimisation phases specifically targeted at recursion another may not for ex ample Of course this is just an example but you would be surprised by how many subtle differences there are between compilers These differences which may make a fast algorithm slow and vice versa We could also factor in the same concerns about languages that target virtual machines leaving all the actual various implementation issues to you given that you will know your lan guages compiler much better than uswell in most cases This has resulted in a more concise book that focuses on what we think are the key issues One final note never take the words of others as gospel verify all that can be feasibly verified and make up your own mind Wehopeyouenjoyreadingthisbookasmuchaswehaveenjoyedwritingit Granville Barnett Luca Del TongoAcknowledgements Writing this short book has been a fun and rewarding experience We would like to thank in no particular order the following people who have helped us during the writing of this book Sonu Kapoor generously hosted our book which when we released the first draft received over thirteen thousand downloads without his generosity this book wouldnot havebeen ableto reachso manypeople Jon Skeetprovidedus with an alarming number of suggestions throughout for which we are eternally grateful Jon also edited this book as well Wewouldalsoliketothankthosewhoprovidedtheoddsuggestionviaemail to us All feedback was listened to and you will no doubt see some content influenced by your suggestions A special thank you also goes out to those who helped publicise this book from Microsofts Channel 9 weekly show thanks Dan to the many bloggers who helped spread the word You gave us an audience and for that we are extremely grateful Thank you to all who contributed in some way to this book The program ming community never ceases to amaze us in howwilling its constituentsare to give time to projects such as this one Thank you VIAbout the Authors Granville Barnett GranvilleiscurrentlyaPhDcandidateatQueenslandUniversityofTechnology QUTworkingonparallelismattheMicrosoftQUTeResearchCentre1 Healso holdsadegreeinComputerScienceandisaMicrosoftMVPHismaininterests are in programming languages and compilers Granville can be contacted via one of two places either his personal website httpgbarnettorg or his blog httpmsmvpscomblogsgbarnett Luca Del Tongo Luca is currently studying for his masters degree in Computer Science at Flo rence His main interests vary from web development to research fields such as data mining and computer vision Luca also maintains an Italian blog which can be found at httpblogsugidotnetorgwetblog 1httpwwwmquterquteduau VIIPage intentionally left blankChapter 1 Introduction 11 What this book is and what it isnt This book provides implementations of common and uncommon algorithms in pseudocodewhichislanguageindependentandprovidesforeasyportingtomost imperative programming languages It is not a definitive book on the theory of data structures and algorithms Forthemostpartthisbookpresentsimplementationsdevisedbytheauthors themselves based on the concepts by which the respective algorithms are based upon so it is more than possible that our implementations differ from those considered the norm You should use this book alongside another on the same subject but one that contains formal proofs of the algorithms in question In this book we use the abstract big Oh notation to depict the run time complexity of algorithms so that the book appeals to a larger audience 12 Assumed knowledge We have written this book with few assumptions of the reader but some have beennecessaryinordertokeepthebookasconciseandapproachableaspossible We assume that the reader is familiar with the following 1 Big Oh notation 2 An imperative programming language 3 Object oriented concepts 121 Big Oh notation ForruntimecomplexityanalysisweusebigOhnotationextensivelysoitisvital that you are familiar with the general concepts to determine which is the best algorithm for you in certain scenarios We have chosen to use big Oh notation for a few reasons the most important of which is that it provides an abstract measurement by which we can judge the performance of algorithms without using mathematical proofs 1CHAPTER 1 INTRODUCTION 2 Figure 11 Algorithmic run time expansion Figure11showssomeoftheruntimestodemonstratehowimportantitisto chooseanefficientalgorithm Forthesanityofourgraphwehaveomittedcubic On3 and exponential O2n run times Cubic and exponential algorithms shouldonlyeverbeusedforverysmallproblemsifeveravoidthemiffeasibly possible The following list explains some of the most common big Oh notations O1 constant theoperationdoesntdependonthesizeofitsinputeg adding a node to the tail of a linked list where we always maintain a pointer to the tail node On linear the run time complexity is proportionate to the size of n Olog n logarithmic normally associated with algorithms that break the problem into smaller chunks per each invocation eg searching a binary search tree On log n justnlogn usuallyassociatedwithanalgorithmthatbreakstheproblem intosmallerchunkspereachinvocationandthentakestheresultsofthese smaller chunks and stitches them back together eg quick sort On2 quadratic eg bubble sort On3 cubic very rare O2n exponential incredibly rare Ifyouencountereitherofthelattertwoitemscubicandexponentialthisis really a signal for you to review the design of your algorithm While prototyp ing algorithm designs you may just have the intention of solving the problem irrespective of how fast it works We would strongly advise that you always review your algorithm design and optimise where possibleparticularly loopsCHAPTER 1 INTRODUCTION 3 and recursive callsso that you can get the most efficient run times for your algorithms The biggest asset that big Oh notation gives us is that it allows us to es sentially discard things like hardware If you have two sorting algorithms one with a quadratic run time and the other with a logarithmic run time then the logarithmic algorithm will always be faster than the quadratic one when the data set becomes suitably large This applies even if the former is ran on a ma chine that is far faster than the latter Why Because big Oh notation isolates a key factor in algorithm analysis growth An algorithm with a quadratic run time grows faster than one with a logarithmic run time It is generally said at some point as n the logarithmic algorithm will become faster than the quadratic algorithm Big Oh notation also acts as a communication tool Picture the scene you are having a meeting with some fellow developers within your product group Youarediscussingprototypealgorithmsfornodediscoveryinmassivenetworks Several minutes elapse after you and two others have discussed your respective algorithms and how they work Does this give you a good idea of how fast each respective algorithm is No The result of such a discussion will tell you more aboutthehighlevelalgorithmdesignratherthanitsefficiency Replaythescene back in your head but this time as well as talking about algorithm design each respective developer states the asymptotic run time of their algorithm Using the latter approach you not only get a good general idea about the algorithm design but also key efficiency data which allows you to make better choices when it comes to selecting an algorithm fit for purpose Some readers may actually work in a product group where they are given budgets per feature Each feature holds with it a budget that represents its up permosttimebound Ifyousavesometimeinonefeatureitdoesntnecessarily give you a buffer for the remaining features Imagine you are working on an application and you are in the team that is developing the routines that will essentially spin up everything that is required when the application is started Everything is great until your boss comes in and tells you that the start up time should not exceed n ms The efficiency of every algorithm that is invoked during start up in this example is absolutely key to a successful product Even if you dont have these budgets you should still strive for optimal solutions Taking a quantitative approach for many software development properties will make you a far superior programmer measuring ones work is critical to success 122 Imperative programming language All examples are given in a pseudoimperative coding format and so the reader must know the basics of some imperative mainstream programming language to port the examples effectively we have written this book with the following target languages in mind 1 C 2 C 3 JavaCHAPTER 1 INTRODUCTION 4 The reason that we are explicit in this requirement is simpleall our imple mentations are based on an imperative thinking style If you are a functional programmeryouwillneedtoapplyvariousaspectsfromthefunctionalparadigm to produce efficient solutions with respect to your functional language whether it be Haskell F OCaml etc Two of the languages that we have listed C and Java target virtual machines which provide various things like security sand boxing and memory management via garbage collection algorithms It is trivial to port our imple mentations to these languages When porting to C you must remember to use pointers for certain things For example when we describe a linked list node as having a reference to the next node this description is in the context of a managed environment In C you should interpret the reference as a pointer to the next node and so on For programmers who have a fair amount of experience with their respective language these subtleties will present no is sue which is why we really do emphasise that the reader must be comfortable with at least one imperative language in order to successfully port the pseudo implementations in this book It is essential that the user is familiar with primitive imperative language constructs before reading this book otherwise you will just get lost Some algo rithms presented in this book can be confusing to follow even for experienced programmers 123 Object oriented concepts For the most part this book does not use features that are specific to any one language In particular we never provide data structures or algorithms that work on generic typesthis is in order to make the samples as easy to follow as possible However to appreciate the designs of our data structures you will need to be familiar with the following object oriented OO concepts 1 Inheritance 2 Encapsulation 3 Polymorphism ThisisespeciallyimportantifyouareplanningonlookingattheCtarget that we have implemented more on that in 17 which makes extensive use of the OO concepts listed above As a final note it is also desirable that the reader is familiar with interfaces as the C target uses interfaces throughout the sorting algorithms 13 Pseudocode Throughout this book we use pseudocode to describe our solutions For the most part interpreting the pseudocode is trivial as it looks very much like a more abstract C or C but there are a few things to point out 1 Preconditions should always be enforced 2 Postconditionsrepresenttheresultofapplyingalgorithmatodatastruc ture dCHAPTER 1 INTRODUCTION 5 3 The type of parameters is inferred 4 All primitive language constructs are explicitly begun and ended If an algorithm has a return type it will often be presented in the post condition but where the return type is sufficiently obvious it may be omitted for the sake of brevity Most algorithms in this book require parameters and because we assign no explicittypetothoseparametersthetypeisinferredfromthecontextsinwhich it is used and the operations performed upon it Additionally the name of the parameter usually acts as the biggest clue to its type For instance n is a pseudoname for a number and so you can assume unless otherwise stated that n translates to an integer that has the same number of bits as a WORD on a 32bitmachinesimilarlyl isapseudonameforalistwherealistisaresizeable array eg a vector Thelastmajorpointofreferenceisthatwealwaysexplicitlyendalanguage construct For instance if we wish to close the scope of a for loop we will explicitly state end for rather than leaving the interpretation of when scopes areclosedtothereader Whileimplicitscopeclosureworkswellinsimplecode in complex cases it can lead to ambiguity Thepseudocodestylethatweusewithinthisbookisratherstraightforward All algorithms start with a simple algorithm signature eg 1 algorithm AlgorithmNamearg1 arg2 argN 2 n end AlgorithmName Immediately after the algorithm signature we list any Pre or Post condi tions 1 algorithm AlgorithmNamen 2 Pre n is the value to compute the factorial of 3 n0 4 Post the factorial of n has been computed 5 n end AlgorithmName The example above describes an algorithm by the name of AlgorithmName which takes a single numeric parameter n The pre and post conditions follow the algorithm signature you should always enforce the preconditions of an algorithm when porting them to your language of choice Normallywhatislistedasapreconiditioniscriticaltothealgorithmsopera tion Thismaycoverthingsliketheactualparameternotbeingnullorthatthe collection passed in must contain at least n items The postcondition mainly describestheeffectofthealgorithmsoperation Anexampleofapostcondition might be The list has been sorted in ascending order Because everything we describe is language independent you will need to make your own mind up on how to best handle preconditions For example in the C target we have implemented we consider nonconformance to pre conditions to be exceptional cases We provide a message in the exception to tell the caller why the algorithm has failed to execute normallyCHAPTER 1 INTRODUCTION 6 14 Tips for working through the examples As with most books you get out what you put in and so we recommend that in order to get the most out of this book you work through each algorithm with a pen and paper to track things like variable names recursive calls etc The best way to work through algorithms is to set up a table and in that tablegiveeachvariableitsowncolumnandcontinuouslyupdatethesecolumns This will help you keep track of and visualise the mutations that are occurring throughout the algorithm Often while working through algorithms in such a way you can intuitively map relationships between data structures rather than trying to work out a few values on paper and the rest in your head We suggest you put everything on paper irrespective of how trivial some variables and calculations may be so that you always have a point of reference When dealing with recursive algorithm traces we recommend you do the same as the above but also have a table that records function calls and who theyreturnto Thisapproachisafarcleanerwaythandrawingoutanelaborate map of function calls with arrows to one another which gets large quickly and simply makes things more complex to follow Track everything in a simple and systematic way to make your time studying the implementations far easier 15 Book outline We have split this book into two parts Part 1 Provides discussion and pseudoimplementations of common and uncom mon data structures and Part 2 Providesalgorithmsofvaryingpurposesfromsortingtostringoperations The reader doesnt have to read the book sequentially from beginning to end chapters can be read independently from one another We suggest that in part 1 you read each chapter in its entirety but in part 2 you can get away with just reading the section of a chapter that describes the algorithm you are interested in Eachofthechaptersondatastructurespresentinitiallythealgorithmscon cerned with 1 Insertion 2 Deletion 3 Searching The previous list represents what we believe in the vast majority of cases to be the most important for each respective data structure For all readers we recommend that before looking at any algorithm you quickly look at Appendix E which contains a table listing the various symbols usedwithinouralgorithmsandtheirmeaning Onekeywordthatwewouldlike to point out here is yield You can think of yield in the same light as return Thereturnkeywordcausesthemethodtoexitandreturnscontroltothecaller whereas yield returns each value to the caller With yield control only returns to the caller when all values to return to the caller have been exhaustedCHAPTER 1 INTRODUCTION 7 16 Testing All the data structures and algorithms have been tested using a minimised test driven development style on paper to flesh out the pseudocode algorithm We then transcribe these tests into unit tests satisfying them one by one When all the test cases have been progressively satisfied we consider that algorithm suitably tested For the most part algorithms have fairly obvious cases which need to be satisfied Some however have many areas which can prove to be more complex tosatisfy Withsuchalgorithmswewillpointoutthetestcaseswhicharetricky andthecorrespondingportionsofpseudocodewithinthealgorithmthatsatisfy that respective case As you become more familiar with the actual problem you will be able to intuitively identify areas which may cause problems for your algorithms imple mentation Thisinsomecaseswillyieldanoverwhelminglistofconcernswhich will hinder your ability to design an algorithm greatly When you are bom barded with such a vast amount of concerns look at the overall problem again andsubdividetheproblemintosmallerproblems Solvingthesmallerproblems and then composing them is a far easier task than clouding your mind with too many little details The only type of testing that we use in the implementation of all that is provided in this book are unit tests Because unit tests contribute such a core piece of creating somewhat more stable software we invite the reader to view Appendix D which describes testing in more depth 17 Where can I get the code This book doesnt provide any code specifically aligned with it however we do actively maintain an open source project1 that houses a C implementation of allthepseudocodelisted TheprojectisnamedDataStructuresandAlgorithms DSA and can be found at httpcodeplexcomdsa 18 Final messages We have just a few final messages to the reader that we hope you digest before you embark on reading this book 1 Understand how the algorithm works first in an abstract sense and 2 Always work through the algorithms on paper to understand how they achieve their outcome Ifyoualwaysfollowthesekeypoints youwillgetthemostoutofthisbook 1All readers are encouraged to provide suggestions feature requests and bugs so we can furtherimproveourimplementationsPart I Data Structures 8Chapter 2 Linked Lists Linked lists can be thought of from a high level perspective as being a series of nodes Each node has at least a single pointer to the next node and in the last nodes case a null pointer representing that there are no more nodes in the linked list In DSA our implementations of linked lists always maintain head and tail pointers so that insertion at either the head or tail of the list is a constant time operation Random insertion is excluded from this and will be a linear operation As such linked lists in DSA have the following characteristics 1 Insertion is O1 2 Deletion is On 3 Searching is On Out of the three operations the one that stands out is that of insertion In DSA we chose to always maintain pointers or more aptly references to the nodes at the head and tail of the linked list and so performing a traditional insertion to either the front or back of the linked list is an O1 operation An exception to this rule is performing an insertion before a node that is neither the head nor tail in a singly linked list When the node we are inserting before is somewhere in the middle of the linked list known as random insertion the complexity is On In order to add before the designated node we need to traverse the linked list to find that nodes current predecessor This traversal yields an On run time Thisdatastructureistrivial butlinkedlistshaveafewkeypointswhichat times make them very attractive 1 thelistisdynamicallyresizedthusitincursnocopypenaltylikeanarray or vector would eventually incur and 2 insertion is O1 21 Singly Linked List Singly linked lists are one of the most primitive data structures you will find in this book Each node that makes up a singly linked list consists of a value and a reference to the next node if any in the list 9CHAPTER 2 LINKED LISTS 10 Figure 21 Singly linked list node Figure 22 A singly linked list populated with integers 211 Insertion In general when people talk about insertion with respect to linked lists of any form they implicitly refer to the adding of a node to the tail of the list When you use an API like that of DSA and you see a general purpose method that addsanodetothelistyoucanassumethatyouareaddingthenodetothetail of the list not the head Adding a node to a singly linked list has only two cases 1 head in which case the node we are adding is now both the head and tail of the list or 2 we simply need to append our node onto the end of the list updating the tail reference appropriately 1 algorithm Addvalue 2 Pre value is the value to add to the list 3 Post value has been placed at the tail of the list 4 n nodevalue 5 if head 6 headn 7 tailn 8 else 9 tailNext n 10 tailn 11 end if 12 end Add As an example of the previous algorithm consider adding the following se quence of integers to the list 1 45 60 and 12 the resulting list is that of Figure 22 212 Searching Searching a linked list is straightforward we simply traverse the list checking the value we are looking for with the value of each node in the linked list The algorithmlistedinthissectionisverysimilartothatusedfortraversalin214CHAPTER 2 LINKED LISTS 11 1 algorithm Containshead value 2 Pre head is the head node in the list 3 value is the value to search for 4 Post the item is either in the linked list true otherwise false 5 nhead 6 while n cid54 and nValue cid54value 7 nnNext 8 end while 9 if n 10 return false 11 end if 12 return true 13 end Contains 213 Deletion Deleting a node from a linked list is straightforward but there are a few cases we need to account for 1 the list is empty or 2 the node to remove is the only node in the linked list or 3 we are removing the head node or 4 we are removing the tail node or 5 the node to remove is somewhere in between the head and tail or 6 the item to remove doesnt exist in the linked list The algorithm whose cases we have described will remove a node from any wherewithinalistirrespectiveofwhetherthenodeistheheadetc Ifyouknow that items will only ever be removed from the head or tail of the list then you can create much more concise algorithms In the case of always removing from the front of the linked list deletion becomes an O1 operationCHAPTER 2 LINKED LISTS 12 1 algorithm Removehead value 2 Pre head is the head node in the list 3 value is the value to remove from the list 4 Post value is removed from the list true otherwise false 5 if head 6 case 1 7 return false 8 end if 9 nhead 10 if nValue value 11 if headtail 12 case 2 13 head 14 tail 15 else 16 case 3 17 headheadNext 18 end if 19 return true 20 end if 21 while nNext cid54 and nNextValue cid54value 22 nnNext 23 end while 24 if nNext cid54 25 if nNext tail 26 case 4 27 tailn 28 end if 29 this is only case 5 if the conditional on line 25 was false 30 nNext nNextNext 31 return true 32 end if 33 case 6 34 return false 35 end Remove 214 Traversing the list Traversing a singly linked list is the same as that of traversing a doubly linked list defined in 22 You start at the head of the list and continue until you come across a node that is The two cases are as follows 1 node we have exhausted all nodes in the linked list or 2 we must update the node reference to be nodeNext The algorithm described is a very simple one that makes use of a simple while loop to check the first caseCHAPTER 2 LINKED LISTS 13 1 algorithm Traversehead 2 Pre head is the head node in the list 3 Post the items in the list have been traversed 4 nhead 5 while n cid540 6 yield nValue 7 nnNext 8 end while 9 end Traverse 215 Traversing the list in reverse order Traversing a singly linked list in a forward manner ie left to right is simple asdemonstratedin214 However whatifwewantedtotraversethenodesin the linked list in reverse order for some reason The algorithm to perform such a traversal is very simple and just like demonstrated in 213 we will need to acquire a reference to the predecessor of a node even though the fundamental characteristics of the nodes that make up a singly linked list make this an expensiveoperation ForeachnodefindingitspredecessorisanOnoperation sooverthecourseoftraversingthewholelistbackwardsthecostbecomesOn2 Figure23depictsthefollowingalgorithmbeingappliedtoalinkedlistwith the integers 5 10 1 and 40 1 algorithm ReverseTraversalhead tail 2 Pre head and tail belong to the same list 3 Post the items in the list have been traversed in reverse order 4 if tail cid54 5 curr tail 6 while curr cid54head 7 prev head 8 while prevNext cid54curr 9 prev prevNext 10 end while 11 yield currValue 12 curr prev 13 end while 14 yield currValue 15 end if 16 end ReverseTraversal This algorithm is only of real interest when we are using singly linked lists as you will soon see that doubly linked lists defined in 22 make reverse list traversal simple and efficient as shown in 223 22 Doubly Linked List Doubly linked lists are very similar to singly linked lists The only difference is that each node has a reference to both the next and previous nodes in the listCHAPTER 2 LINKED LISTS 14 Figure 23 Reverse traveral of a singly linked list Figure 24 Doubly linked list nodeCHAPTER 2 LINKED LISTS 15 The following algorithms for the doubly linked list are exactly the same as those listed previously for the singly linked list 1 Searching defined in 212 2 Traversal defined in 214 221 Insertion The only major difference between the algorithm in 211 is that we need to remember to bind the previous pointer of n to the previous tail node if n was not the first node to be inserted into the list 1 algorithm Addvalue 2 Pre value is the value to add to the list 3 Post value has been placed at the tail of the list 4 n nodevalue 5 if head 6 headn 7 tailn 8 else 9 nPrevious tail 10 tailNext n 11 tailn 12 end if 13 end Add Figure 25 shows the doubly linked list after adding the sequence of integers defined in 211 Figure 25 Doubly linked list populated with integers 222 Deletion As you may of guessed the cases that we use for deletion in a doubly linked list are exactly the same as those defined in 213 Like insertion we have the added task of binding an additional reference Previous to the correct valueCHAPTER 2 LINKED LISTS 16 1 algorithm Removehead value 2 Pre head is the head node in the list 3 value is the value to remove from the list 4 Post value is removed from the list true otherwise false 5 if head 6 return false 7 end if 8 if valueheadValue 9 if headtail 10 head 11 tail 12 else 13 headheadNext 14 headPrevious 15 end if 16 return true 17 end if 18 nheadNext 19 while n cid54 and value cid54nValue 20 nnNext 21 end while 22 if ntail 23 tailtailPrevious 24 tailNext 25 return true 26 else if n cid54 27 nPreviousNext nNext 28 nNextPrevious nPrevious 29 return true 30 end if 31 return false 32 end Remove 223 Reverse Traversal Singlylinkedlistshaveaforwardonlydesignwhichiswhythereversetraversal algorithmdefinedin215requiredsomecreativeinvention Doublylinkedlists make reverse traversal as simple as forward traversal defined in 214 except thatwestartatthetailnodeandupdatethepointersintheoppositedirection Figure 26 shows the reverse traversal algorithm in actionCHAPTER 2 LINKED LISTS 17 Figure 26 Doubly linked list reverse traversal 1 algorithm ReverseTraversaltail 2 Pre tail is the tail node of the list to traverse 3 Post the list has been traversed in reverse order 4 ntail 5 while ncid54 6 yield nValue 7 nnPrevious 8 end while 9 end ReverseTraversal 23 Summary Linked lists are good to use when you have an unknown number of items to store Using a data structure like an array would require you to specify the size up front exceeding that size involves invoking a resizing algorithm which has a linear run time You should also use linked lists when you will only remove nodes at either the head or tail of the list to maintain a constant run time This requires maintaining pointers to the nodes at the head and tail of the list but the memory overhead will pay for itself if this is an operation you will be performing many times What linked lists are not very good for is random insertion accessing nodes by index and searching At the expense of a little memory in most cases 4 bytes would suffice and a few more readwrites you could maintain a count variable that tracks how many items are contained in the list so that accessing such a primitive property is a constant operation you just need to update count during the insertion and deletion algorithms Singly linked lists should be used when you are only performing basic in sertions In general doubly linked lists are more accommodating for nontrivial operations on a linked list We recommend the use of a doubly linked list when you require forwards and backwards traversal For the most cases this requirement is present For example consider a token stream that you want to parse in a recursive descent fashion Sometimes you will have to backtrack in order to create the correct parse tree In this scenario a doubly linked list is best as its design makes bidirectional traversal much simpler and quicker than that of a singly linkedCHAPTER 2 LINKED LISTS 18 listChapter 3 Binary Search Tree BinarysearchtreesBSTsareverysimpletounderstand Westartwitharoot node with value x where the left subtree of x contains nodes with values x and the right subtree contains nodes whose values are x Each node follows the same rules with respect to nodes in their left and right subtrees BSTsareofinterestbecausetheyhaveoperationswhicharefavourablyfast insertionlookupanddeletioncanallbedoneinOlog ntime Itisimportant to note that the Olog n times for these operations can only be attained if the BST is reasonably balanced for a tree data structure with self balancing properties see AVL tree defined in 7 In the following examples you can assume unless used as a parameter alias that root is a reference to the root node of the tree 23 14 31 7 17 9 Figure 31 Simple unbalanced binary search tree 19CHAPTER 3 BINARY SEARCH TREE 20 31 Insertion As mentioned previously insertion is an Olog n operation provided that the tree is moderately balanced 1 algorithm Insertvalue 2 Pre value has passed custom type checks for type T 3 Post value has been placed in the correct location in the tree 4 if root 5 root nodevalue 6 else 7 InsertNoderoot value 8 end if 9 end Insert 1 algorithm InsertNodecurrent value 2 Pre current is the node to start from 3 Post value has been placed in the correct location in the tree 4 if valuecurrentValue 5 if currentLeft 6 currentLeft nodevalue 7 else 8 InsertNodecurrentLeft value 9 end if 10 else 11 if currentRight 12 currentRight nodevalue 13 else 14 InsertNodecurrentRight value 15 end if 16 end if 17 end InsertNode The insertion algorithm is split for a good reason The first algorithm non recursive checks a very core base case whether or not the tree is empty If the tree is empty then we simply create our root node and finish In all other cases we invoke the recursive InsertNode algorithm which simply guides us to the first appropriate place in the tree to put value Note that at each stage we perform a binary chop we either choose to recurse into the left subtree or the rightbycomparingthenewvaluewiththatofthecurrentnode Foranytotally ordered type no value can simultaneously satisfy the conditions to place it in both subtreesCHAPTER 3 BINARY SEARCH TREE 21 32 Searching SearchingaBSTisevensimplerthaninsertion Thepseudocodeisselfexplanatory but we will look briefly at the premise of the algorithm nonetheless Wehavetalkedpreviouslyaboutinsertionwegoeitherleftorrightwiththe right subtree containing values that are x where x is the value of the node we are inserting When searching the rules are made a little more atomic and at any one time we have four cases to consider 1 the root in which case value is not in the BST or 2 rootValue value in which case value is in the BST or 3 valuerootValue we must inspect the left subtree of root for value or 4 valuerootValue we must inspect the right subtree of root for value 1 algorithm Containsroot value 2 Pre root is the root node of the tree value is what we would like to locate 3 Post value is either located or not 4 if root 5 return false 6 end if 7 if rootValue value 8 return true 9 else if valuerootValue 10 return ContainsrootLeft value 11 else 12 return ContainsrootRight value 13 end if 14 end ContainsCHAPTER 3 BINARY SEARCH TREE 22 33 Deletion Removing a node from a BST is fairly straightforward with four cases to con sider 1 the value to remove is a leaf node or 2 the value to remove has a right subtree but no left subtree or 3 the value to remove has a left subtree but no right subtree or 4 the value to remove has both a left and right subtree in which case we promote the largest value in the left subtree There is also an implicit fifth case whereby the node to be removed is the only node in the tree This case is already covered by the first but should be noted as a possibility nonetheless Of course in a BST a value may occur more than once In such a case the first occurrence of that value in the BST will be removed 4 Right subtree 23 and left subtree 3 Left subtree 14 31 no right subtree 2 Right subtree 7 no left subtree 1 Leaf Node 9 Figure 32 binary search tree deletion cases The Remove algorithm given below relies on two further helper algorithms named FindParent and FindNode which are described in 34 and 35 re spectivelyCHAPTER 3 BINARY SEARCH TREE 23 1 algorithm Removevalue 2 Pre value is the value of the node to remove root is the root node of the BST 3 Count is the number of items in the BST 3 Post node with value is removed if found in which case yields true otherwise false 4 nodeToRemove FindNodevalue 5 if nodeToRemove 6 return false value not in BST 7 end if 8 parent FindParentvalue 9 if Count 1 10 root we are removing the only node in the BST 11 else if nodeToRemoveLeft and nodeToRemoveRight null 12 case 1 13 if nodeToRemoveValue parentValue 14 parentLeft 15 else 16 parentRight 17 end if 18 else if nodeToRemoveLeft and nodeToRemoveRight cid54 19 case 2 20 if nodeToRemoveValue parentValue 21 parentLeft nodeToRemoveRight 22 else 23 parentRight nodeToRemoveRight 24 end if 25 else if nodeToRemoveLeft cid54 and nodeToRemoveRight 26 case 3 27 if nodeToRemoveValue parentValue 28 parentLeft nodeToRemoveLeft 29 else 30 parentRight nodeToRemoveLeft 31 end if 32 else 33 case 4 34 largestValuenodeToRemoveLeft 35 while largestValueRight cid54 36 find the largest value in the left subtree of nodeToRemove 37 largestValuelargestValueRight 38 end while 39 set the parents Right pointer of largestValue to 40 FindParentlargestValueValueRight 41 nodeToRemoveValue largestValueValue 42 end if 43 Count Count 1 44 return true 45 end RemoveCHAPTER 3 BINARY SEARCH TREE 24 34 Finding the parent of a given node The purpose of this algorithm is simple to return a reference or pointer to the parent node of the one with the given value We have found that such an algorithm is very useful especially when performing extensive tree transforma tions 1 algorithm FindParentvalue root 2 Pre value is the value of the node we want to find the parent of 3 root is the root node of the BST and is 4 Post a reference to the parent node of value if found otherwise 5 if valuerootValue 6 return 7 end if 8 if valuerootValue 9 if rootLeft 10 return 11 else if rootLeftValue value 12 return root 13 else 14 return FindParentvalue rootLeft 15 end if 16 else 17 if rootRight 18 return 19 else if rootRightValue value 20 return root 21 else 22 return FindParentvalue rootRight 23 end if 24 end if 25 end FindParent A special case in the above algorithm is when the specified value does not existintheBSTinwhichcasewereturn Callerstothisalgorithmmusttake account of this possibility unless they are already certain that a node with the specified value exists 35 Attaining a reference to a node Thisalgorithmisverysimilarto34butinsteadofreturningareferencetothe parent of the node with the specified value it returns a reference to the node itself Again is returned if the value isnt foundCHAPTER 3 BINARY SEARCH TREE 25 1 algorithm FindNoderoot value 2 Pre value is the value of the node we want to find the parent of 3 root is the root node of the BST 4 Post a reference to the node of value if found otherwise 5 if root 6 return 7 end if 8 if rootValue value 9 return root 10 else if valuerootValue 11 return FindNoderootLeft value 12 else 13 return FindNoderootRight value 14 end if 15 end FindNode Astute readers will have noticed that the FindNode algorithm is exactly the same as the Contains algorithm defined in 32 with the modification that we are returning a reference to a node not true or false Given FindNode the easiest way of implementing Contains is to call FindNode and compare the return value with 36 Finding the smallest and largest values in the binary search tree To find the smallest value in a BST you simply traverse the nodes in the left subtree of the BST always going left upon each encounter with a node termi natingwhenyoufindanodewithnoleftsubtree Theoppositeisthecasewhen findingthelargestvalueintheBSTBothalgorithmsareincrediblysimpleand are listed simply for completeness ThebasecaseinbothFindMinandFindMaxalgorithmsiswhentheLeft FindMin or Right FindMax node references are in which case we have reached the last node 1 algorithm FindMinroot 2 Pre root is the root node of the BST 3 root cid54 4 Post the smallest value in the BST is located 5 if rootLeft 6 return rootValue 7 end if 8 FindMinrootLeft 9 end FindMinCHAPTER 3 BINARY SEARCH TREE 26 1 algorithm FindMaxroot 2 Pre root is the root node of the BST 3 root cid54 4 Post the largest value in the BST is located 5 if rootRight 6 return rootValue 7 end if 8 FindMaxrootRight 9 end FindMax 37 Tree Traversals There are various strategies which can be employed to traverse the items in a tree the choice of strategy depends on which node visitation order you require In this section we will touch on the traversals that DSA provides on all data structures that derive from BinarySearchTree 371 Preorder Whenusingthepreorderalgorithmyouvisittherootfirstthentraversetheleft subtree and finally traverse the right subtree An example of preorder traversal is shown in Figure 33 1 algorithm Preorderroot 2 Pre root is the root node of the BST 3 Post the nodes in the BST have been visited in preorder 4 if root cid54 5 yield rootValue 6 PreorderrootLeft 7 PreorderrootRight 8 end if 9 end Preorder 372 Postorder This algorithm is very similar to that described in 371 however the value of the node is yielded after traversing both subtrees An example of postorder traversal is shown in Figure 34 1 algorithm Postorderroot 2 Pre root is the root node of the BST 3 Post the nodes in the BST have been visited in postorder 4 if root cid54 5 PostorderrootLeft 6 PostorderrootRight 7 yield rootValue 8 end if 9 end PostorderCHAPTER 3 BINARY SEARCH TREE 27 23 23 23 14 31 14 31 14 31 7 17 7 17 7 17 9 9 9 a b c 23 23 23 14 31 14 31 14 31 7 17 7 17 7 17 9 9 9 d e f Figure 33 Preorder visit binary search tree exampleCHAPTER 3 BINARY SEARCH TREE 28 23 23 23 14 31 14 31 14 31 7 17 7 17 7 17 9 9 9 a b c 23 23 23 14 31 14 31 14 31 7 17 7 17 7 17 9 9 9 d e f Figure 34 Postorder visit binary search tree exampleCHAPTER 3 BINARY SEARCH TREE 29 373 Inorder Anothervariationofthealgorithmsdefinedin371and372isthatofinorder traversal where the value of the current node is yielded in between traversing theleftsubtreeandtherightsubtree Anexampleofinordertraversalisshown in Figure 35 23 23 23 14 31 14 31 14 31 7 17 7 17 7 17 9 9 9 a b c 23 23 23 14 31 14 31 14 31 7 17 7 17 7 17 9 9 9 d e f Figure 35 Inorder visit binary search tree example 1 algorithm Inorderroot 2 Pre root is the root node of the BST 3 Post the nodes in the BST have been visited in inorder 4 if root cid54 5 InorderrootLeft 6 yield rootValue 7 InorderrootRight 8 end if 9 end Inorder One of the beauties of inorder traversal is that values are yielded in their comparison order In other words when traversing a populated BST with the inorder strategy the yielded sequence would have property x x i i i1CHAPTER 3 BINARY SEARCH TREE 30 374 Breadth First Traversing a tree in breadth first order yields the values of all nodes of a par ticular depth in the tree before any deeper ones In other words given a depth d we would visit the values of all nodes at d in a left to right fashion then we would proceed to d1 and so on until we hade no more nodes to visit An example of breadth first traversal is shown in Figure 36 Traditionally breadth first traversal is implemented using a list vector re sizeablearray etctostorethevaluesofthenodesvisitedinbreadthfirstorder and then a queue to store those nodes that have yet to be visited 23 23 23 14 31 14 31 14 31 7 17 7 17 7 17 9 9 9 a b c 23 23 23 14 31 14 31 14 31 7 17 7 17 7 17 9 9 9 d e f Figure 36 Breadth First visit binary search tree exampleCHAPTER 3 BINARY SEARCH TREE 31 1 algorithm BreadthFirstroot 2 Pre root is the root node of the BST 3 Post the nodes in the BST have been visited in breadth first order 4 q queue 5 while root cid54 6 yield rootValue 7 if rootLeft cid54 8 qEnqueuerootLeft 9 end if 10 if rootRight cid54 11 qEnqueuerootRight 12 end if 13 if qIsEmpty 14 rootqDequeue 15 else 16 root 17 end if 18 end while 19 end BreadthFirst 38 Summary Abinarysearchtreeisagoodsolutionwhenyouneedtorepresenttypesthatare orderedaccordingtosomecustomrulesinherenttothattype Withlogarithmic insertion lookup and deletion it is very effecient Traversal remains linear but there are many ways in which you can visit the nodes of a tree Trees are recursive data structures so typically you will find that many algorithms that operate on a tree are recursive Theruntimespresentedinthischapterarebasedonaprettybigassumption that the binary search trees left and right subtrees are reasonably balanced We can only attain logarithmic run times for the algorithms presented earlier when this is true A binary search tree does not enforce such a property and the run times for these operations on a pathologically unbalanced tree become linear such a tree is effectively just a linked list Later in 7 we will examine an AVL tree that enforces selfbalancing properties to help attain logarithmic run timesChapter 4 Heap Aheapcanbethoughtofasasimpletreedatastructurehoweveraheapusually employs one of two strategies 1 min heap or 2 max heap Each strategy determines the properties of the tree and its values If you weretochoosetheminheapstrategytheneachparentnodewouldhaveavalue that is than its children For example the node at the root of the tree will have the smallest value in the tree The opposite is true for the max heap strategy In this book you should assume that a heap employs the min heap strategy unless otherwise stated Unlikeothertreedatastructuresliketheonedefinedin3aheapisgenerally implemented as an array rather than a series of nodes which each have refer ences to other nodes The nodes are conceptually the same however having at most two children Figure 41 shows how the tree not a heap data structure 1273269 wouldberepresentedasanarray ThearrayinFigure41isa result of simply adding values in a toptobottom lefttoright fashion Figure 42 shows arrows to the direct left and right child of each value in the array Thischapterisverymuchcentredaroundthenotionofrepresentingatreeas an array and because this property is key to understanding this chapter Figure 43 shows a step by step process to represent a tree data structure as an array In Figure 43 you can assume that the default capacity of our array is eight Usingjustanarrayisoftennotsufficientaswehavetobeupfrontaboutthe sizeofthearraytousefortheheap Oftentheruntimebehaviourofaprogram can be unpredictable when it comes to the size of its internal data structures soweneedtochooseamoredynamicdatastructurethatcontainsthefollowing properties 1 we can specify an initial size of the array for scenarios where we know the upper storage limit required and 2 the data structure encapsulates resizing algorithms to grow the array as required at run time 32CHAPTER 4 HEAP 33 Figure 41 Array representation of a simple tree data structure Figure42 Directchildrenofthenodesinanarrayrepresentationofatreedata structure 1 Vector 2 ArrayList 3 List Figure 41 does not specify how we would handle adding null references to the heap This varies from case to case sometimes null values are prohibited entirely in other cases we may treat them as being smaller than any nonnull value or indeed greater than any nonnull value You will have to resolve this ambiguityyourselfhavingstudiedyourrequirements Forthesakeofclaritywe will avoid the issue by prohibiting null values Because we are using an array we need some way to calculate the index of a parent node and the children of a node The required expressions for this are defined as follows for a node at index 1 index12 parent index 2 2index1 left child 3 2index2 right child In Figure 44 a represents the calculation of the right child of 12 202 and b calculates the index of the parent of 3 312 41 Insertion Designing an algorithm for heap insertion is simple but we must ensure that heap order is preserved after each insertion Generally this is a postinsertion operation Insertingavalueintothenextfreeslotinanarrayissimple wejust needtokeeptrackofthenextfreeindexinthearrayasacounterandincrement it after each insertion Inserting our value into the heap is the first part of the algorithmthesecondisvalidatingheaporder Inthecaseofminheapordering this requires us to swap the values of a parent and its child if the value of the child is the value of its parent We must do this for each subtree containing the value we just insertedCHAPTER 4 HEAP 34 Figure 43 Converting a tree data structure to its array counterpartCHAPTER 4 HEAP 35 Figure 44 Calculating node properties The run time efficiency for heap insertion is Olog n The run time is a by product of verifying heap order as the first part of the algorithm the actual insertion into the array is O1 Figure 45 shows the steps of inserting the values 3 9 12 7 and 1 into a minheapCHAPTER 4 HEAP 36 Figure 45 Inserting values into a minheapCHAPTER 4 HEAP 37 1 algorithm Addvalue 2 Pre value is the value to add to the heap 3 Count is the number of items in the heap 4 Post the value has been added to the heap 5 heapCount value 6 Count Count 1 7 MinHeapify 8 end Add 1 algorithm MinHeapify 2 Pre Count is the number of items in the heap 3 heap is the array used to store the heap items 4 Post the heap has preserved min heap ordering 5 i Count 1 6 while i0 and heapi heapi12 7 Swapheapi heapi12 8 i i12 9 end while 10 end MinHeapify The design of the MaxHeapify algorithm is very similar to that of the Min Heapify algorithm the only difference is that the operator in the second condition of entering the while loop is changed to 42 Deletion Just as for insertion deleting an item involves ensuring that heap ordering is preserved The algorithm for deletion has three steps 1 find the index of the value to delete 2 put the last value in the heap at the index location of the item to delete 3 verify heap ordering for each subtree which used to include the valueCHAPTER 4 HEAP 38 1 algorithm Removevalue 2 Pre value is the value to remove from the heap 3 left and right are updated alias for 2index1 and 2index2 respectively 4 Count is the number of items in the heap 5 heap is the array used to store the heap items 6 Post value is located in the heap and removed true otherwise false 7 step 1 8 index FindIndexheap value 9 if index0 10 return false 11 end if 12 Count Count 1 13 step 2 14 heapindex heapCount 15 step 3 16 while left Count and heapindex heapleft or heapindex heapright 17 promote smallest key from subtree 18 if heapleft heapright 19 Swapheap left index 20 indexleft 21 else 22 Swapheap right index 23 indexright 24 end if 25 end while 26 return true 27 end Remove Figure 46 shows the Remove algorithm visually removing 1 from a heap containing the values 1 3 9 12 and 13 In Figure 46 you can assume that we havespecifiedthatthebackingarrayoftheheapshouldhaveaninitialcapacity of eight Pleasenotethatinourdeletionalgorithmthatwedontdefaulttheremoved value in the heap array If you are using a heap for reference types ie objects thatareallocatedonaheapyouwillwanttofreethatmemory Thisisimportant in both unmanaged and managed languages In the latter we will want to null that empty hole so that the garbage collector can reclaim that memory If we were to not null that hole then the object could still be reached and thus wont be garbage collected 43 Searching Searching a heap is merely a matter of traversing the items in the heap array sequentially so this operation has a run time complexity of On The search can be thought of as one that uses a breadth first traversal as defined in 374 to visit the nodes within the heap to check for the presence of a specified itemCHAPTER 4 HEAP 39 Figure 46 Deleting an item from a heapCHAPTER 4 HEAP 40 1 algorithm Containsvalue 2 Pre value is the value to search the heap for 3 Count is the number of items in the heap 4 heap is the array used to store the heap items 5 Post value is located in the heap in which case true otherwise false 6 i0 7 while i Count and heapi cid54value 8 ii1 9 end while 10 if i Count 11 return true 12 else 13 return false 14 end if 15 end Contains The problem with the previous algorithm is that we dont take advantage of the properties in which all values of a heap hold that is the property of the heap strategy being used For instance if we had a heap that didnt contain the value4wewouldhavetoexhaustthewholebackingheaparraybeforewecould determine that it wasnt present in the heap Factoring in what we know about the heap we can optimise the search algorithm by including logic which makes use of the properties presented by a certain heap strategy Optimising to deterministically state that a value is in the heap is not that straightforward however the problem is a very interesting one As an example consideraminheapthatdoesntcontainthevalue5 Wecanonlyrulethatthe value is not in the heap if 5 the parent of the current node being inspected and the current node being inspected nodes at the current level we are traversing If this is the case then 5 cannot be in the heap and so we can provide an answer without traversing the rest of the heap If this property is not satisfied for any level of nodes that we are inspecting then the algorithm will indeed fall back to inspecting all the nodes in the heap The optimisation that we present can be very common and so we feel that the extra logic within the loop is justified to prevent the expensive worse case run time Thefollowingalgorithmisspecificallydesignedforaminheap Totailorthe algorithmforamaxheapthetwocomparisonoperationsintheelseif condition within the inner while loop should be flippedCHAPTER 4 HEAP 41 1 algorithm Containsvalue 2 Pre value is the value to search the heap for 3 Count is the number of items in the heap 4 heap is the array used to store the heap items 5 Post value is located in the heap in which case true otherwise false 6 start0 7 nodes1 8 while start Count 9 startnodes1 10 endnodesstart 11 count0 12 while start Count and startend 13 if valueheapstart 14 return true 15 else if value Parentheapstart and valueheapstart 16 countcount1 17 end if 18 startstart1 19 end while 20 if countnodes 21 return false 22 end if 23 nodesnodes2 24 end while 25 return false 26 end Contains The new Contains algorithm determines if the value is not in the heap by checking whether count nodes In such an event where this is true then we can confirm that nodes n at level ivalue Parentn valuen thus there isnopossiblewaythatvalueisintheheap AsanexampleconsiderFigure47 If we are searching for the value 10 within the minheap displayed it is obvious that we dont need to search the whole heap to determine 9 is not present We can verify this after traversing the nodes in the second level of the heap as the previous expression defined holds true 44 Traversal As mentioned in 43 traversal of a heap is usually done like that of any other array data structure which our heap implementation is based upon As a result you traverse the array starting at the initial array index 0 in most languages and then visit each value within the array until you have reached the upper boundoftheheap YouwillnotethatinthesearchalgorithmthatweuseCount as this upper bound rather than the actual physical bound of the allocated array Count is used to partition the conceptual heap from the actual array implementation of the heap we only care about the items in the heap not the whole arraythe latter may contain various other bits of data as a result of heap mutationCHAPTER 4 HEAP 42 Figure47 Determining10isnotintheheapafterinspectingthenodesofLevel 2 Figure 48 Living and dead space in the heap backing array If you have followed the advice we gave in the deletion algorithm then a heap that has been mutated several times will contain some form of default value for items no longer in the heap Potentially you will have at most LengthOfheapArrayCount garbage values in the backing heap array data structure The garbage values of course vary from platform to platform To make things simple the garbage value of a reference type will be simple and 0 for a value type Figure48showsaheapthatyoucanassumehasbeenmutatedmanytimes Forthisexamplewecanfurtherassumethatatsomepointtheitemsinindexes 3 5 actually contained references to live objects of type T In Figure 48 subscript is used to disambiguate separate objects of T From what you have read thus far you will most likely have picked up that traversing the heap in any other order would be of little benefit The heap property only holds for the subtree of each node and so traversing a heap in any other fashion requires some creative intervention Heaps are not usually traversed in any other way than the one prescribed previously 45 Summary Heaps are most commonly used to implement priority queues see 62 for a sample implementation and to facilitate heap sort As discussed in both the insertion 41 and deletion 42 sections a heap maintains heap order according to the selected ordering strategy These strategies are referred to as minheapCHAPTER 4 HEAP 43 and max heap The former strategy enforces that the value of a parent node is less than that of each of its children the latter enforces that the value of the parent is greater than that of each of its children Whenyoucomeacrossaheapandyouarenottoldwhatstrategyitenforces you should assume that it uses the minheap strategy If the heap can be configured otherwise eg to use maxheap then this will often require you to state this explicitly The heap abides progressively to a strategy during the invocationoftheinsertionanddeletionalgorithms Thecostofsuchapolicyis thatuponeachinsertionanddeletionweinvokealgorithmsthathavelogarithmic run time complexities While the cost of maintaining the strategy might not seem overly expensive it does still come at a price We will also have to factor in the cost of dynamic array expansion at some stage This will occur if the number of items within the heap outgrows the space allocated in the heaps backingarray Itmaybeinyourbestinteresttoresearchagoodinitialstarting size for your heap array This will assist in minimising the impact of dynamic array resizingChapter 5 Sets A set contains a number of values in no particular order The values within the set are distinct from one another Generally set implementations tend to check that a value is not in the set before adding it avoiding the issue of repeated values from ever occurring Thissectiondoesnotcoversettheoryindepthratheritdemonstratesbriefly thewaysinwhichthevaluesofsetscanbedefinedandcommonoperationsthat may be performed upon them ThenotationA479120definesasetAwhosevaluesarelistedwithin the curly braces Given the set A defined previously we can say that 4 is a member of A denoted by 4A and that 99 is not a member of A denoted by 99 A Often defining a set by manually stating its members is tiresome and more importantly the set may contain a large number of values A more concise way of defining a set and its members is by providing a series of properties that the values of the set must satisfy For example from the definition A xx 0x 2 0 the set A contains only positive integers that are even x is an alias to the current value we are inspecting and to the right hand side of are the properties that x must satisfy to be in the set A In this example x must be0andtheremainderofthearithmeticexpressionx2mustbe0 Youwill beabletonotefromthepreviousdefinitionofthesetAthatthesetcancontain an infinite number of values and that the values of the set A will be all even integersthatareamemberofthenaturalnumberssetNwhereN123 Finally in this brief introduction to sets we will cover set intersection and union both of which are very common operations amongst many others per formed on sets The union set can be defined as follows AB x x A or x B and intersection AB x x A and x B Figure 51 demonstrates set intersection and union graphically GiventhesetdefinitionsA123andB 629theunionofthetwo setsisAB 12369andtheintersectionofthetwosetsisAB 2 Both set union and intersection are sometimes provided within the frame work associated with mainstream languages This is the case in NET 351 where such algorithms exist as extension methods defined in the type Sys temLinqEnumerable2 as a result DSA does not provide implementations of 1httpwwwmicrosoftcomNET 2httpmsdnmicrosoftcomenuslibrarysystemlinqenumerable_membersaspx 44CHAPTER 5 SETS 45 Figure 51 a AB b AB these algorithms Most of the algorithms defined in SystemLinqEnumerable deal mainly with sequences rather than sets exclusively Setunioncanbeimplementedasasimpletraversalofbothsetsaddingeach item of the two sets to a new union set 1 algorithm Unionset1 set2 2 Pre set1 and set2cid54 3 union is a set 3 Post A union of set1 and set2 has been created 4 foreach item in set1 5 unionAdditem 6 end foreach 7 foreach item in set2 8 unionAdditem 9 end foreach 10 return union 11 end Union The run time of our Union algorithm is Omn where m is the number of items in the first set and n is the number of items in the second set This runtime applies only to sets that exhibit O1 insertions Set intersection is also trivial to implement The only major thing worth pointing out about our algorithm is that we traverse the set containing the fewest items We can do this because if we have exhausted all the items in the smaller of the two sets then there are no more items that are members of both sets thus we have no more items to add to the intersection setCHAPTER 5 SETS 46 1 algorithm Intersectionset1 set2 2 Pre set1 and set2cid54 3 intersection and smallerSet are sets 3 Post An intersection of set1 and set2 has been created 4 if set1Count set2Count 5 smallerSetset1 6 else 7 smallerSetset2 8 end if 9 foreach item in smallerSet 10 if set1Containsitem and set2Containsitem 11 intersectionAdditem 12 end if 13 end foreach 14 return intersection 15 end Intersection The run time of our Intersection algorithm is On where n is the number of items in the smaller of the two sets Just like our Union algorithm a linear runtime can only be attained when operating on a set with O1 insertion 51 Unordered Sets in the general sense do not enforce the explicit ordering of their mem bers For example the members of B 629 conform to no ordering scheme because it is not required Most libraries provide implementations of unordered sets and so DSA does not we simply mention it here to disambiguate between an unordered set and ordered set We will only look at insertion for an unordered set and cover briefly why a hash table is an efficient data structure to use for its implementation 511 Insertion Anunorderedsetcanbeefficientlyimplementedusingahashtableasitsbacking data structure As mentioned previously we only add an item to a set if that item is not already in the set so the backing data structure we use must have a quick look up and insertion run time complexity A hash map generally provides the following 1 O1 for insertion 2 approaching O1 for look up The above depends on how good the hashing algorithm of the hash table is but most hash tables employ incredibly efficient general purpose hashing algorithms and so the run time complexities for the hash table in your library of choice should be very similar in terms of efficiencyCHAPTER 5 SETS 47 52 Ordered An ordered set is similar to an unordered set in the sense that its members are distinct but an ordered set enforces some predefined comparison on each of its members to produce a set whose members are ordered appropriately In DSA 05 and earlier we used a binary search tree defined in 3 as the internal backing data structure for our ordered set From versions 06 onwards we replaced the binary search tree with an AVL tree primarily because AVL is balanced The ordered set has its order realised by performing an inorder traversal upon its backing tree data structure which yields the correct ordered sequence of set members Because an ordered set in DSA is simply a wrapper for an AVL tree that additionally ensures that the tree contains unique items you should read 7 to learn more about the run time complexities associated with its operations 53 Summary Sets provide a way of having a collection of unique objects either ordered or unordered When implementing a set either ordered or unordered it is key to select the correct backing data structure As we discussed in 511 because we check first if the item is already contained within the set before adding it we need this check to be as quick as possible For unordered sets we can rely on the use of a hash table and use the key of an item to determine whether or not it is alreadycontainedwithintheset Usingahashtablethischeckresultsinanear constant run time complexity Ordered sets cost a little more for this check however the logarithmic growth that we incur by using a binary search tree as its backing data structure is acceptable Anotherkeypropertyofsetsimplementedusingtheapproachwedescribeis that both have favourably fast lookup times Just like the check before inser tionforahashtablethisruntimecomplexityshouldbenearconstant Ordered sets as described in 3 perform a binary chop at each stage when searching for the existence of an item yielding a logarithmic run time Wecanusesetstofacilitatemanyalgorithmsthatwouldotherwisebealittle less clear in their implementation For example in 114 we use an unordered set to assist in the construction of an algorithm that determines the number of repeated words within a stringChapter 6 Queues Queues are an essential data structure that are found in vast amounts of soft ware from user mode to kernel mode applications that are core to the system Fundamentally they honour a first in first out FIFO strategy that is the item first put into the queue will be the first served the second item added to the queue will be the second to be served and so on A traditional queue only allows you to access the item at the front of the queue when you add an item to the queue that item is placed at the back of the queue Historically queues always have the following three core methods Enqueue places an item at the back of the queue Dequeue retrievestheitematthefrontofthequeueandremovesitfromthe queue Peek 1 retrieves the item at the front of the queue without removing it from the queue Asanexampletodemonstratethebehaviourofaqueuewewillwalkthrough ascenariowherebyweinvokeeachofthepreviouslymentionedmethodsobserv ing the mutations upon the queue data structure The following list describes the operations performed upon the queue in Figure 61 1 Enqueue10 2 Enqueue12 3 Enqueue9 4 Enqueue8 5 Enqueue3 6 Dequeue 7 Peek 1ThisoperationissometimesreferredtoasFront 48CHAPTER 6 QUEUES 49 8 Enqueue33 9 Peek 10 Dequeue 61 A standard queue A queue is implicitly like that described prior to this section In DSA we dont provide a standard queue because queues are so popular and such a core data structure that you will find pretty much every mainstream library provides a queue data structure that you can use with your language of choice In this section we will discuss how you can if required implement an efficient queue data structure The main property of a queue is that we have access to the item at the front of the queue The queue data structure can be efficiently implemented using a singly linked list defined in 21 A singly linked list provides O1 insertion and deletion run time complexities The reason we have an O1 run timecomplexityfordeletionisbecauseweonlyeverremoveitemsfromthefront of queues with the Dequeue operation Since we always have a pointer to the item at the head of a singly linked list removal is simply a case of returning the value of the old head node and then modifying the head pointer to be the next node of the old head node The run time complexity for searching a queue remains the same as that of a singly linked list On 62 Priority Queue Unlike a standard queue where items are ordered in terms of who arrived first a priority queue determines the order of its items by using a form of custom comparer to see which item has the highest priority Other than the items in a priorityqueuebeingorderedbypriorityitremainsthesameasanormalqueue you can only access the item at the front of the queue Asensibleimplementationofapriorityqueueistouseaheapdatastructure definedin4 Usingaheapwecanlookatthefirstiteminthequeuebysimply returningtheitematindex0withintheheaparray Aheapprovidesuswiththe ability to construct a priority queue where the items with the highest priority are either those with the smallest value or those with the largest 63 Double Ended Queue Unlike the queues we have talked about previously in this chapter a double ended queue allows you to access the items at both the front and back of the queue Adoubleendedqueueiscommonlyknownasadequewhichisthename we will here on in refer to it as A deque applies no prioritization strategy to its items like a priority queue does items are added in order to either the front of back of the deque The formerpropertiesofthedequearedenotedbytheprogrammerutilisingthedata structures exposed interfaceCHAPTER 6 QUEUES 50 Figure 61 Queue mutationsCHAPTER 6 QUEUES 51 Dequesprovidefrontandbackspecificversionsofcommonqueueoperations eg you may want to enqueue an item to the front of the queue rather than the back in which case you would use a method with a name along the lines of EnqueueFront The following list identifies operations that are commonly supported by deques EnqueueFront EnqueueBack DequeueFront DequeueBack PeekFront PeekBack Figure 62 shows a deque after the invocation of the following methods in order 1 EnqueueBack12 2 EnqueueFront1 3 EnqueueBack23 4 EnqueueFront908 5 DequeueFront 6 DequeueBack The operations have a onetoone translation in terms of behaviour with those of a normal queue or priority queue In some cases the set of algorithms that add an item to the back of the deque may be named as they are with normalqueueseg EnqueueBack maysimplybecalledEnqueue ansoon Some frameworksalsospecifyexplicitbehavioursthatdatastructuresmustadhereto ThisiscertainlythecaseinNETwheremostcollectionsimplementaninterface which requires the data structure to expose a standard Add method In such a scenario you can safely assume that the Add method will simply enqueue an item to the back of the deque With respect to algorithmic run time complexities a deque is the same as a normal queue That is enqueueing an item to the back of a the queue is O1 additionally enqueuing an item to the front of the queue is also an O1 operation A deque is a wrapper data structure that uses either an array or a doubly linked list Using an array as the backing data structure would require the pro grammer to be explicit about the size of the array up front this would provide anobviousadvantageiftheprogrammercoulddeterministicallystatethemaxi mum number of items the deque would contain at any one time Unfortunately in most cases this doesnt hold as a result the backing array will inherently incur the expense of invoking a resizing algorithm which would most likely be an On operation Such an approach would also leave the library developerCHAPTER 6 QUEUES 52 Figure 62 Deque data structure after several mutationsCHAPTER 6 QUEUES 53 to look at array minimization techniques as well it could be that after several invocations of the resizing algorithm and various mutations on the deque later that we have an array taking up a considerable amount of memory yet we are only using a few small percentage of that memory An algorithm described would also be On yet its invocation would be harder to gauge strategically To bypass all the aforementioned issues a deque typically uses a doubly linked list as its baking data structure While a node that has two pointers consumesmorememorythanitsarrayitemcounterpartitmakesredundantthe need for expensive resizing algorithms as the data structure increases in size dynamically With a language that targets a garbage collected virtual machine memory reclamation is an opaque process as the nodes that are no longer ref erenced become unreachable and are thus marked for collection upon the next invocation of the garbage collection algorithm With C or any other lan guagethatusesexplicitmemoryallocationanddeallocationitwillbeuptothe programmer to decide when the memory that stores the object can be freed 64 Summary Withnormalqueueswehaveseenthatthosewhoarrivefirstaredealtwithfirst that is they are dealt with in a firstinfirstout FIFO order Queues can be ever so useful for example the Windows CPU scheduler uses a different queue for each priority of process to determine which should be the next process to utilise the CPU for a specified time quantum Normal queues have constant insertion and deletion run times Searching a queue is fairly unusualtypically you are only interested in the item at the front of the queue Despite that searching is usually exposed on queues and typically the run time is linear In this chapter we have also seen priority queues where those at the front of the queue have the highest priority and those near the back have the lowest One implementation of a priority queue is to use a heap data structure as its backing store so the run times for insertion deletion and searching are the same as those for a heap defined in 4 Queuesareaverynaturaldatastructureandwhiletheyarefairlyprimitive they can make many problems a lot simpler For example the breadth first search defined in 374 makes extensive use of queuesChapter 7 AVL Tree In the early 60s GM AdelsonVelsky and EM Landis invented the first self balancing binary search tree data structure calling it AVL Tree AnAVLtreeisabinarysearchtreeBSTdefinedin3withaselfbalancing condition stating that the difference between the height of the left and right subtrees cannot be no more than one see Figure 71 This condition restored after each tree modification forces the general shape of an AVL tree Before continuing let us focus on why balance is so important Consider a binary search tree obtained by starting with an empty tree and inserting some values in the following order 12345 The BST in Figure 72 represents the worst case scenario in which the run ning time of all common operations such as search insertion and deletion are On By applying a balance condition we ensure that the worst case running time of each common operation is Olog n The height of an AVL tree with n nodes is Olog n regardless of the order in which values are inserted TheAVLbalanceconditionknownalsoasthenodebalancefactorrepresents an additional piece of information stored for each node This is combined with a technique that efficiently restores the balance condition for the tree In an AVLtreetheinventorsmakeuseofawellknowntechniquecalledtreerotation h h1 Figure 71 The left and right subtrees of an AVL tree differ in height by at most 1 54CHAPTER 7 AVL TREE 55 1 2 3 4 5 Figure 72 Unbalanced binary search tree 2 4 1 4 2 5 3 5 1 3 a b Figure 73 Avl trees insertion order a12345 b15432CHAPTER 7 AVL TREE 56 71 Tree Rotations Atreerotationisaconstanttimeoperationonabinarysearchtreethatchanges theshapeofatreewhilepreservingstandardBSTproperties Thereareleftand right rotations both of them decrease the height of a BST by moving smaller subtrees down and larger subtrees up 14 8 RightRotation 8 24 2 14 LeftRotation 2 11 11 24 Figure 74 Tree left and right rotationsCHAPTER 7 AVL TREE 57 1 algorithm LeftRotationnode 2 Pre nodeRight 3 Post nodeRight is the new root of the subtree 4 node has become nodeRights left child and 5 BST properties are preserved 6 RightNode nodeRight 7 nodeRight RightNodeLeft 8 RightNodeLeft node 9 end LeftRotation 1 algorithm RightRotationnode 2 Pre nodeLeft 3 Post nodeLeft is the new root of the subtree 4 node has become nodeLefts right child and 5 BST properties are preserved 6 LeftNode nodeLeft 7 nodeLeft LeftNodeRight 8 LeftNodeRight node 9 end RightRotation The right and left rotation algorithms are symmetric Only pointers are changed by a rotation resulting in an O1 runtime complexity the other fields present in the nodes are not changed 72 Tree Rebalancing The algorithm that we present in this section verifies that the left and right subtrees differ at most in height by 1 If this property is not present then we perform the correct rotation Notice that we use two new algorithms that represent double rotations These algorithms are named LeftAndRightRotation and RightAndLeftRotation The algorithms are self documenting in their names eg LeftAndRightRotation first performs a left rotation and then subsequently a right rotationCHAPTER 7 AVL TREE 58 1 algorithm CheckBalancecurrent 2 Pre current is the node to start from balancing 3 Post current height has been updated while tree balance is if needed 4 restored through rotations 5 if currentLeft and currentRight 6 currentHeight 1 7 else 8 currentHeight MaxHeightcurrentLeftHeightcurrentRight 1 9 end if 10 if HeightcurrentLeft HeightcurrentRight 1 11 if HeightcurrentLeftLeft HeightcurrentLeftRight 0 12 RightRotationcurrent 13 else 14 LeftAndRightRotationcurrent 15 end if 16 else if HeightcurrentLeft HeightcurrentRight 1 17 if HeightcurrentRightLeft HeightcurrentRightRight 0 18 LeftRotationcurrent 19 else 20 RightAndLeftRotationcurrent 21 end if 22 end if 23 end CheckBalance 73 Insertion AVL insertion operates first by inserting the given value the same way as BST insertion and then by applying rebalancing techniques if necessary The latter isonlyperformediftheAVLpropertynolongerholds thatistheleftandright subtrees height differ by more than 1 Each time we insert a node into an AVL tree 1 Wegodownthetreetofindthecorrectpointatwhichtoinsertthenode in the same manner as for BST insertion then 2 we travel up the tree from the inserted node and check that the node balancing property has not been violated if the property hasnt been violated then we need not rebalance the tree the opposite is true if the balancing property has been violatedCHAPTER 7 AVL TREE 59 1 algorithm Insertvalue 2 Pre value has passed custom type checks for type T 3 Post value has been placed in the correct location in the tree 4 if root 5 root nodevalue 6 else 7 InsertNoderoot value 8 end if 9 end Insert 1 algorithm InsertNodecurrent value 2 Pre current is the node to start from 3 Post value has been placed in the correct location in the tree while 4 preserving tree balance 5 if valuecurrentValue 6 if currentLeft 7 currentLeft nodevalue 8 else 9 InsertNodecurrentLeft value 10 end if 11 else 12 if currentRight 13 currentRight nodevalue 14 else 15 InsertNodecurrentRight value 16 end if 17 end if 18 CheckBalancecurrent 19 end InsertNode 74 Deletion OurbalancingalgorithmisliketheonepresentedforourBSTdefinedin33 The major difference is that we have to ensure that the tree still adheres to the AVL balance property after the removal of the node If the tree doesnt need to be rebalanced and the value we are removing is contained within the tree then no further step are required However when the value is in the tree and its removal upsets the AVL balance property then we must perform the correct rotationsCHAPTER 7 AVL TREE 60 1 algorithm Removevalue 2 Pre value is the value of the node to remove root is the root node 3 of the Avl 4 Post node with value is removed and tree rebalanced if found in which 5 case yields true otherwise false 6 nodeToRemoveroot 7 parent 8 Stackpath root 9 while nodeToRemovecid54 and nodeToRemoveValueValue 10 parent nodeToRemove 11 if valuenodeToRemoveValue 12 nodeToRemove nodeToRemoveLeft 13 else 14 nodeToRemove nodeToRemoveRight 15 end if 16 pathPushnodeToRemove 17 end while 18 if nodeToRemove 19 return false value not in Avl 20 end if 21 parent FindParentvalue 22 if count1 count keeps track of the of nodes in the Avl 23 root we are removing the only node in the Avl 24 else if nodeToRemoveLeft and nodeToRemoveRight null 25 case 1 26 if nodeToRemoveValue parentValue 27 parentLeft 28 else 29 parentRight 30 end if 31 else if nodeToRemoveLeft and nodeToRemoveRight cid54 32 case 2 33 if nodeToRemoveValue parentValue 34 parentLeft nodeToRemoveRight 35 else 36 parentRight nodeToRemoveRight 37 end if 38 else if nodeToRemoveLeft cid54 and nodeToRemoveRight 39 case 3 40 if nodeToRemoveValue parentValue 41 parentLeft nodeToRemoveLeft 42 else 43 parentRight nodeToRemoveLeft 44 end if 45 else 46 case 4 47 largestValuenodeToRemoveLeft 48 while largestValueRight cid54 49 find the largest value in the left subtree of nodeToRemove 50 largestValuelargestValueRightCHAPTER 7 AVL TREE 61 51 end while 52 set the parents Right pointer of largestValue to 53 FindParentlargestValueValueRight 54 nodeToRemoveValue largestValueValue 55 end if 56 while pathCount0 57 CheckBalancepathPop we trackback to the root node check balance 58 end while 59 countcount1 60 return true 61 end Remove 75 Summary The AVL tree is a sophisticated self balancing tree It can be thought of as the smarter younger brother of the binary search tree Unlike its older brother the AVL tree avoids worst case linear complexity runtimes for its operations The AVL tree guarantees via the enforcement of balancing algorithms that the left and right subtrees differ in height by at most 1 which yields at most a logarithmic runtime complexityPart II Algorithms 62Chapter 8 Sorting All the sorting algorithms in this chapter use data structures of a specific type to demonstrate sorting eg a 32 bit integer is often used as its associated operations eg etc are clear in their behaviour The algorithms discussed can easily be translated into generic sorting algo rithms within your respective language of choice 81 Bubble Sort One of the most simple forms of sorting is that of comparing each item with every other item in some list however as the description may imply this form of sorting is not particularly effecient On2 In its most simple form bubble sort can be implemented as two loops 1 algorithm BubbleSortlist 2 Pre list cid54 3 Post list has been sorted into values of ascending order 4 for i0 to listCount1 5 for j 0 to listCount1 6 if listilistj 7 Swaplistilistj 8 end if 9 end for 10 end for 11 return list 12 end BubbleSort 82 Merge Sort Merge sort is an algorithm that has a fairly efficient space time complexity Onlognandisfairlytrivialtoimplement Thealgorithmisbasedonsplitting alistintotwosimilarsizedlistsleftandrightandsortingeachlistandthen merging the sorted lists back together Note the function MergeOrdered simply takes two ordered lists and makes them one 63CHAPTER 8 SORTING 64 4 75 74 2 54 4 75 74 2 54 4 74 75 2 54 4 74 2 75 54 4 74 2 54 75 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 4 74 2 54 75 4 74 2 54 75 4 2 74 54 75 4 2 54 74 75 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 4 2 54 74 75 2 4 54 74 75 2 4 54 74 75 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 2 4 54 74 75 2 4 54 74 75 0 1 2 3 4 0 1 2 3 4 2 4 54 74 75 0 1 2 3 4 Figure 81 Bubble Sort Iterations 1 algorithm Mergesortlist 2 Pre list cid54 3 Post list has been sorted into values of ascending order 4 if listCount 1 already sorted 5 return list 6 end if 7 mlistCount 2 8 left listm 9 right listlistCount m 10 for i0 to leftCount1 11 lefti listi 12 end for 13 for i0 to rightCount1 14 righti listi 15 end for 16 left Mergesortleft 17 right Mergesortright 18 return MergeOrderedleft right 19 end MergesortCHAPTER 8 SORTING 65 4 4 4 2 75 75 4 4 75 54 75 74 74 74 75 2 2 74 54 54 2 2 74 54 2 2 54 54 5 4 Divide ImperaMerge Figure 82 Merge Sort Divide et Impera Approach 83 Quick Sort Quick sort is one of the most popular sorting algorithms based on divide et imperastrategyresultinginanOnlog ncomplexity Thealgorithmstartsby picking an item called pivot and moving all smaller items before it while all greaterelementsafterit Thisisthemainquicksortoperationcalledpartition recursively repeated on lesser and greater sub lists until their size is one or zero in which case the list is implicitly sorted Choosinganappropriatepivot asforexamplethemedianelementisfunda mental for avoiding the drastically reduced performance of On2CHAPTER 8 SORTING 66 4 75 74 2 54 Pivot 4 75 74 2 54 Pivot 4 54 74 2 75 Pivot 4 2 74 54 75 Pivot 4 2 54 74 75 Pivot 4 2 74 75 Pivot Pivot 2 4 74 75 Pivot Pivot 2 4 54 74 75 Figure 83 Quick Sort Example pivot median strategy 1 algorithm QuickSortlist 2 Pre list cid54 3 Post list has been sorted into values of ascending order 4 if listCount 1 already sorted 5 return list 6 end if 7 pivotMedianValuelist 8 for i0 to listCount1 9 if listipivot 10 equalInsertlisti 11 end if 12 if listipivot 13 lessInsertlisti 14 end if 15 if listipivot 16 greaterInsertlisti 17 end if 18 end for 19 return ConcatenateQuickSortless equal QuickSortgreater 20 end QuicksortCHAPTER 8 SORTING 67 84 Insertion Sort Insertionsortisasomewhatinterestingalgorithmwithanexpensiveruntimeof On2 It can be best thought of as a sorting scheme similar to that of sorting a hand of playing cards ie you take one card and then look at the rest with the intent of building up an ordered set of cards in your hand 4 75 74 4 75 74 2 54 4 75 74 2 54 4 75 74 2 54 2 54 4 74 75 2 54 2 4 74 75 54 2 4 54 74 75 Figure 84 Insertion Sort Iterations 1 algorithm Insertionsortlist 2 Pre list cid54 3 Post list has been sorted into values of ascending order 4 unsorted1 5 while unsortedlistCount 6 holdlistunsorted 7 iunsorted1 8 while i0 and holdlisti 9 listi1 listi 10 ii1 11 end while 12 listi1 hold 13 unsortedunsorted1 14 end while 15 return list 16 end InsertionsortCHAPTER 8 SORTING 68 85 Shell Sort Put simply shell sort can be thought of as a more efficient variation of insertion sort as described in 84 it achieves this mainly by comparing items of varying distances apart resulting in a run time complexity of On log2 n Shell sort is fairly straight forward but may seem somewhat confusing at first as it differs from other sorting algorithms in the way it selects items to compare Figure 85 shows shell sort being ran on an array of integers the red coloured square is the current value we are holding 1 algorithm ShellSortlist 2 Pre list cid54 3 Post list has been sorted into values of ascending order 4 incrementlistCount 2 5 while increment cid540 6 currentincrement 7 while currentlistCount 8 holdlistcurrent 9 icurrentincrement 10 while i0 and holdlisti 11 listiincrement listi 12 iincrement 13 end while 14 listiincrement hold 15 currentcurrent1 16 end while 17 increment 2 18 end while 19 return list 20 end ShellSort 86 Radix Sort Unlike the sorting algorithms described previously radix sort uses buckets to sort items each bucket holds items with a particular property called a key Normally a bucket is a queue each time radix sort is performed these buckets are emptied starting the smallest key bucket to the largest When looking at itemswithinalisttosortwedosobyisolatingaspecifickeyeg intheexample we are about to show we have a maximum of three keys for all items that is the highest key we need to look at is hundreds Because we are dealing with in this example base 10 numbers we have at any one point 10 possible key values 09 each of which has their own bucket Before we show you this first simple version of radix sort let us clarify what we mean by isolating keys Given the number 102 if we look at the first key the ones then we can see we have two of them progressing to the next key tens we can see that the number has zero of them finally we can see that the number has a single hundred The number used as an example has in total three keysCHAPTER 8 SORTING 69 Figure 85 Shell sortCHAPTER 8 SORTING 70 1 Ones 2 Tens 3 Hundreds Forfurtherclarificationwhatifwewantedtodeterminehowmanythousands the number 102 has Clearly there are none but often looking at a number as final like we often do it is not so obvious so when asked the question how many thousands does 102 have you should simply pad the number with a zero in that location eg 0102 here it is more obvious that the key value at the thousands location is zero The last thing to identify before we actually show you a simple implemen tation of radix sort that works on only positive integers and requires you to specify the maximum key size in the list is that we need a way to isolate a specific key at any one time The solution is actually very simple but its not often you want to isolate a key in a number so we will spell it out clearly here A key can be accessed from any integer with the following expression key number keyToAccess 10 As a simple example lets say that we want to access the tens key of the number 1290 the tens column is key 10 and so after substitution yields key 1290 10 10 9 The next key to lookatforanumbercanbeattainedbymultiplyingthelastkeybytenworking left to right in a sequential manner The value of key is used in the following algorithmtoworkouttheindexofanarrayofqueuestoenqueuetheiteminto 1 algorithm Radixlist maxKeySize 2 Pre list cid54 3 maxKeySize0 and represents the largest key size in the list 4 Post list has been sorted 5 queues Queue10 6 indexOfKey 1 7 fori0 to maxKeySize1 8 foreach item in list 9 queuesGetQueueIndexitem indexOfKeyEnqueueitem 10 end foreach 11 list CollapseQueuesqueues 12 ClearQueuesqueues 13 indexOfKey indexOfKey10 14 end for 15 return list 16 end Radix Figure86showsthemembersofqueuesfromthealgorithmdescribedabove operating on the list whose members are 90128791123 and 61 the key we are interested in for each number is highlighted Omitted queues in Figure 86 mean that they contain no items 87 Summary Throughout this chapter we have seen many different algorithms for sorting lists some are very efficient eg quick sort defined in 83 some are not egCHAPTER 8 SORTING 71 Figure 86 Radix sort base 10 algorithm bubble sort defined in 81 Selectingthecorrectsortingalgorithmisusuallydenotedpurelybyefficiency eg you would always choose merge sort over shell sort and so on There are also other factors to look at though and these are based on the actual imple mentation Some algorithms are very nicely expressed in a recursive fashion howeverthesealgorithmsoughttobeprettyefficienteg implementingalinear quadratic or slower algorithm using recursion would be a very bad idea If you want to learn more about why you should be very very careful when implementing recursive algorithms see Appendix CChapter 9 Numeric Unless stated otherwise the alias n denotes a standard 32 bit integer 91 Primality Test A simple algorithm that determines whether or not a given integer is a prime number eg 2 5 7 and 13 are all prime numbers however 6 is not as it can be the result of the product of two numbers that are 6 In an attempt to slow down the inner loop the n is used as the upper bound 1 algorithm IsPrimen 2 Post n is determined to be a prime or not 3 for i2 to n do 4 for j 1 to sqrtn do 5 if ij n 6 return false 7 end if 8 end for 9 end for 10 end IsPrime 92 Base conversions DSA contains a number of algorithms that convert a base 10 number to its equivalent binary octal or hexadecimal form For example 78 has a binary 10 representation of 1001110 2 Table 91 shows the algorithm trace when the number to convert to binary is 742 10 72CHAPTER 9 NUMERIC 73 1 algorithm ToBinaryn 2 Pre n0 3 Post n has been converted into its base 2 representation 4 while n0 5 listAddn 2 6 nn2 7 end while 8 return Reverselist 9 end ToBinary n list 742 0 371 01 185 011 92 0110 46 01101 23 011011 11 0110111 5 01101111 2 011011110 1 0110111101 Table 91 Algorithm trace of ToBinary 93 Attaining the greatest common denomina tor of two numbers Afairlyroutineprobleminmathematicsisthatoffindingthegreatestcommon denominatoroftwointegerswhatweareessentiallyafteristhegreatestnumber which is a multiple of both eg the greatest common denominator of 9 and 15 is 3 One of the most elegant solutions to this problem is based on Euclids algorithm that has a run time complexity of On2 1 algorithm GreatestCommonDenominatorm n 2 Pre m and n are integers 3 Post the greatest common denominator of the two integers is calculated 4 if n0 5 return m 6 end if 7 return GreatestCommonDenominatorn m n 8 end GreatestCommonDenominatorCHAPTER 9 NUMERIC 74 94 Computing the maximum value for a num ber of a specific base consisting of N digits This algorithm computes the maximum value of a number for a given number of digits eg using the base 10 system the maximum number we can have made up of 4 digits is the number 9999 Similarly the maximum number that 10 consists of 4 digits for a base 2 number is 1111 which is 15 2 10 The expression by which we can compute this maximum value for N digits is BN 1 In the previous expression B is the number base and N is the numberofdigits Asanexampleifwewantedtodeterminethemaximumvalue for a hexadecimal number base 16 consisting of 6 digits the expression would be as follows 1661 The maximum value of the previous example would be represented as FFFFFF which yields 16777215 16 10 In the following algorithm numberBase should be considered restricted to the values of 2 8 9 and 16 For this reason in our actual implementation numberBase has an enumeration type The Base enumeration type is defined as BaseBinary 2Octal8Decimal10Hexadecimal16 Thereasonweprovidethedefinitionof Base istogiveyouanideahowthis algorithmcanbemodelledinamorereadablemannerratherthanusingvarious checkstodeterminethecorrectbasetouse Forourimplementationwecastthe valueofnumberBasetoanintegerassuchweextractthevalueassociatedwith the relevant option in the Base enumeration As an example if we were to cast theoptionOctal toanintegerwewouldgetthevalue8 Inthealgorithmlisted below the cast is implicit so we just use the actual argument numberBase 1 algorithm MaxValuenumberBase n 2 Pre numberBase is the number system to use n is the number of digits 3 Post the maximum value for numberBase consisting of n digits is computed 4 return PowernumberBasen 1 5 end MaxValue 95 Factorial of a number Attainingthefactorialofanumberisaprimitivemathematicaloperation Many implementations of the factorial algorithm are recursive as the problem is re cursive in nature however here we present an iterative solution The iterative solution is presented because it too is trivial to implement and doesnt suffer from the use of recursion for more on recursion see C Thefactorialof0and1is0 Theaforementionedactsasabasecasethatwe will build upon The factorial of 2 is 2 the factorial of 1 similarly the factorial of 3 is 3 the factorial of 2 and so on We can indicate that we are after the factorial of a number using the form N where N is the number we wish to attain the factorial of Our algorithm doesnt use such notation but it is handy to knowCHAPTER 9 NUMERIC 75 1 algorithm Factorialn 2 Pre n0 n is the number to compute the factorial of 3 Post the factorial of n is computed 4 if n2 5 return 1 6 end if 7 factorial1 8 for i2 to n 9 factorialfactoriali 10 end for 11 return factorial 12 end Factorial 96 Summary In this chapter we have presented several numeric algorithms most of which are simply here because they were fun to design Perhaps the message that the reader should gain from this chapter is that algorithms can be applied to several domains to make work in that respective domain attainable Numeric algorithmsinparticulardrivesomeofthemostadvancedsystemsontheplanet computing such data as weather forecastsChapter 10 Searching 101 Sequential Search A simple algorithm that search for a specific item inside a list It operates looping on each element On until a match occurs or the end is reached 1 algorithm SequentialSearchlist item 2 Pre list cid54 3 Post return index of item if found otherwise 1 4 index0 5 while indexlistCount and listindex cid54 item 6 indexindex1 7 end while 8 if indexlistCount and listindex item 9 return index 10 end if 11 return 1 12 end SequentialSearch 102 Probability Search Probability search is a statistical sequential searching algorithm In addition to searching for an item it takes into account its frequency by swapping it with its predecessor in the list The algorithm complexity still remains at On but inanonuniformitemssearchthemorefrequentitemsareinthefirstpositions reducing list scanning time Figure 101 shows the resulting state of a list after searching for two items notice how the searched items have had their search probability increased after each search operation respectively 76CHAPTER 10 SEARCHING 77 Figure 101 a Search12 b Search101 1 algorithm ProbabilitySearchlist item 2 Pre list cid54 3 Post a boolean indicating where the item is found or not in the former case swap founded item with its predecessor 4 index0 5 while indexlistCount and listindex cid54 item 6 indexindex1 7 end while 8 if indexlistCount or listindex cid54 item 9 return false 10 end if 11 if index0 12 Swaplistindexlistindex1 13 end if 14 return true 15 end ProbabilitySearch 103 Summary In this chapter we have presented a few novel searching algorithms We have presented more efficient searching algorithms earlier on like for instance the logarithmic searching algorithm that AVL and BST trees use defined in 32 We decided not to cover a searching algorithm known as binary chop another name for binary search binary chop usually refers to its array counterpart asCHAPTER 10 SEARCHING 78 the reader has already seen such an algorithm in 3 Searching algorithms and their efficiency largely depends on the underlying data structure being used to store the data For instance it is quicker to deter minewhetheranitemisinahashtablethanitisanarraysimilarlyitisquicker tosearchaBSTthanitisalinkedlist Ifyouaregoingtosearchfordatafairly oftenthenwestronglyadvisethatyousitdownandresearchthedatastructures available to you In most cases using a list or any other primarily linear data structure is down to lack of knowledge Model your data and then research the data structures that best fit your scenarioChapter 11 Strings Strings have their own chapter in this text purely because string operations and transformations are incredibly frequent within programs The algorithms presented are based on problems the authors have come across previously or were formulated to satisfy curiosity 111 Reversing the order of words in a sentence Defining algorithms for primitive string operations is simple eg extracting a substring of a string however some algorithms that require more inventiveness can be a little more tricky The algorithm presented here does not simply reverse the characters in a string rather it reverses the order of words within a string This algorithm works on the principal that words are all delimited by white space and using a few markers to define where words start and end we can easily reverse them 79CHAPTER 11 STRINGS 80 1 algorithm ReverseWordsvalue 2 Pre value cid54 sb is a string buffer 3 Post the words in value have been reversed 4 lastvalueLength 1 5 startlast 6 while last0 7 skip whitespace 8 while start0 and valuestart whitespace 9 startstart1 10 end while 11 laststart 12 march down to the index before the beginning of the word 13 while start0 and start cid54 whitespace 14 startstart1 15 end while 16 append chars from start1 to length1 to string buffer sb 17 for istart1 to last 18 sbAppendvaluei 19 end for 20 if this isnt the last word in the string add some whitespace after the word in the buffer 21 if start0 22 sbAppend 23 end if 24 laststart1 25 startlast 26 end while 27 check if we have added one too many whitespace to sb 28 if sbsbLength 1 whitespace 29 cut the whitespace 30 sbLength sbLength 1 31 end if 32 return sb 33 end ReverseWords 112 Detecting a palindrome Although not a frequent algorithm that will be applied in reallife scenarios detecting a palindrome is a fun and as it turns out pretty trivial algorithm to design The algorithm that we present has a On run time complexity Our algo rithmusestwopointersatoppositeendsofstringwearecheckingisapalindrome or not These pointers march in towards each other always checking that each charactertheypointtoisthesamewithrespecttovalue Figure111showsthe IsPalindrome algorithminoperationonthestringWasitEliotstoiletIsaw If you remove all punctuation and white space from the aforementioned string you will find that it is a valid palindromeCHAPTER 11 STRINGS 81 Figure 111 left and right pointers marching in towards one another 1 algorithm IsPalindromevalue 2 Pre value cid54 3 Post value is determined to be a palindrome or not 4 wordvalueStripToUpperCase 5 left0 6 rightwordLength 1 7 while wordleft wordright and leftright 8 leftleft1 9 rightright1 10 end while 11 return wordleft wordright 12 end IsPalindrome In the IsPalindrome algorithm we call a method by the name of Strip This algorithmdiscardspunctuationinthestringincludingwhitespace Asaresult word contains a heavily compacted representation of the original string each character of which is in its uppercase representation Palindromesdiscardwhitespacepunctuationandcasemakingthesechanges allowsustodesignasimplealgorithmwhilemakingouralgorithmfairlyrobust with respect to the palindromes it will detect 113 Counting the number of words in a string Countingthenumberofwordsinastringcanseemprettytrivialatfirsthowever there are a few cases that we need to be aware of 1 tracking when we are in a string 2 updating the word count at the correct place 3 skipping white space that delimits the words AsanexampleconsiderthestringBenatehayClearlythisstringcontains three words each of which distinguished via white space All of the previously listed points can be managed by using three variables 1 index 2 wordCount 3 inWordCHAPTER 11 STRINGS 82 Figure 112 String with three words Figure 113 String with varying number of white space delimiting the words Of the previously listed index keeps track of the current index we are at in thestring wordCountisanintegerthatkeepstrackofthenumberofwordswe have encountered and finally inWord is a Boolean flag that denotes whether or not at the present time we are within a word If we are not currently hitting white space we are in a word the opposite is true if at the present index we are hitting white space What denotes a word In our algorithm each word is separated by one or more occurrences of white space We dont take into account any particular splitting symbols you may use eg in NET StringSplit1 can take a char or array of characters that determines a delimiter to use to split the characters within the string into chunks of strings resulting in an array of substrings InFigure112wepresentastringindexedasanarray Typicallythepattern is the same for most words delimited by a single occurrence of white space Figure 113 shows the same string with the same number of words but with varying white space splitting them 1httpmsdnmicrosoftcomenuslibrarysystemstringsplitaspxCHAPTER 11 STRINGS 83 1 algorithm WordCountvalue 2 Pre value cid54 3 Post the number of words contained within value is determined 4 inWordtrue 5 wordCount0 6 index0 7 skip initial white space 8 while valueindex whitespace and indexvalueLength 1 9 indexindex1 10 end while 11 was the string just whitespace 12 if indexvalueLength and valueindex whitespace 13 return 0 14 end if 15 while indexvalueLength 16 if valueindex whitespace 17 skip all whitespace 18 while valueindex whitespace and indexvalueLength 1 19 indexindex1 20 end while 21 inWordfalse 22 wordCountwordCount1 23 else 24 inWordtrue 25 end if 26 indexindex1 27 end while 28 last word may have not been followed by whitespace 29 if inWord 30 wordCountwordCount1 31 end if 32 return wordCount 33 end WordCount 114 Determining the number of repeated words within a string With the help of an unordered set and an algorithm that can split the words within a string using a specified delimiter this algorithm is straightforward to implement If we split all the words using a single occurrence of white space as our delimiter we get all the words within the string back as elements of an array Then if we iterate through these words adding them to a set which containsonlyuniquestringswecanattainthenumberofuniquewordsfromthe string All that is left to do is subtract the unique word count from the total number of stings contained in the array returned from the split operation The split operation that we refer to is the same as that mentioned in 113CHAPTER 11 STRINGS 84 Figure 114 a Undesired uniques set b desired uniques set 1 algorithm RepeatedWordCountvalue 2 Pre value cid54 3 Post the number of repeated words in value is returned 4 wordsvalueSplit 5 uniques Set 6 foreach word in words 7 uniquesAddwordStrip 8 end foreach 9 return wordsLength uniquesCount 10 end RepeatedWordCount You will notice in the RepeatedWordCount algorithm that we use the Strip method we referred to earlier in 111 This simply removes any punctuation from a word The reason we perform this operation on each word is so that we can build a more accurate unique string collection eg test and test arethesamewordminusthepunctuation Figure114showstheundesiredand desired sets for the unique set respectively 115 Determining the first matching character between two strings Thealgorithmtodeterminewhetheranycharacterofastringmatchesanyofthe charactersinanotherstringisprettytrivial Putsimplywecanparsethestrings considered using a double loop and check discarding punctuation the equality between any characters thus returning a nonnegative index that represents the location of the first character in the match Figure 115 otherwise we return 1 if no match occurs This approach exhibit a run time complexity of On2CHAPTER 11 STRINGS 85 i i i Word t e s t t e s t t e s t 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 index index index Match p t e r s p t e r s p t e r s 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 a b c Figure 115 a First Step b Second Step c Match Occurred 1 algorithm Anywordmatch 2 Pre wordmatch cid54 3 Post index representing match location if occured 1 otherwise 4 for i0 to wordLength1 5 while wordi whitespace 6 ii1 7 end while 8 for index0 to matchLength1 9 while matchindex whitespace 10 indexindex1 11 end while 12 if matchindex wordi 13 return index 14 end if 15 end for 16 end for 17 return 1 18 end Any 116 Summary We hope that the reader has seen how fun algorithms on string data types are Strings are probably the most common data type and data structure rememberwearedealingwithanarraythatyouwillworkwithsoitsimportant that you learn to be creative with them We for one find strings fascinating A simple Google search on string nuances between languages and encodings will provide you with a great number of problems Now that we have spurred you alongalittlewithourintroductoryalgorithmsyoucandevisesomeofyourownAppendix A Algorithm Walkthrough Learning how to design good algorithms can be assisted greatly by using a structuredapproachtotracingitsbehaviour Inmostcasestracinganalgorithm only requires a single table In most cases tracing is not enough you will also want to use a diagram of the data structure your algorithm operates on This diagram will be used to visualise the problem more effectively Seeing things visually can help you understand the problem quicker and better Thetracetablewillstoreinformationaboutthevariablesusedinyouralgo rithm The values within this table are constantly updated when the algorithm mutates them Such an approach allows you to attain a history of the various values each variable has held You may also be able to infer patterns from the values each variable has contained so that you can make your algorithm more efficient We have found this approach both simple and powerful By combining a visual representation of the problem as well as having a history of past values generated by the algorithm it can make understanding and solving problems much easier In this chapter we will show you how to work through both iterative and recursive algorithms using the technique outlined A1 Iterative algorithms We will trace the IsPalindrome algorithm defined in 112 as our example iterative walkthrough Before we even look at the variables the algorithm uses first we will look at the actual data structure the algorithm operates on It should be pretty obvious that we are operating on a string but how is this represented A string is essentially a block of contiguous memory that consists of some char data types one after the other Each character in the string can be accessed via an index much like you would do when accessing items within an array The picture should be presenting itself a string can be thought of as an array of characters For our example we will use IsPalindrome to operate on the string Never odd or even Now we know how the string data structure is represented and the value of the string we will operate on lets go ahead and draw it as shown in Figure A1 86APPENDIX A ALGORITHM WALKTHROUGH 87 Figure A1 Visualising the data structure we are operating on value word left right Table A1 A column for each variable we wish to track TheIsPalindrome algorithmusesthefollowinglistofvariablesinsomeform throughout its execution 1 value 2 word 3 left 4 right Having identified the values of the variables we need to keep track of we simply create a column for each in a table as shown in Table A1 Now using the IsPalindrome algorithm execute each statement updating the variable values in the table appropriately Table A2 shows the final table values for each variable used in IsPalindrome respectively While this approach may look a little bloated in print on paper it is much more compact Where we have the strings in the table you should annotate these strings with array indexes to aid the algorithm walkthrough There is one other point that we should clarify at this time whether to include variables that change only a few times or not at all in the trace table In Table A2 we have included both the value and word variables because it was convenient to do so You may find that you want to promote these values to a larger diagram like that in Figure A1 and only use the trace table for variables whose values change during the algorithm We recommend that you promote the core data structure being operated on to a larger diagram outside of the table so that you can interrogate it more easily value word left right Never odd or even NEVERODDOREVEN 0 13 1 12 2 11 3 10 4 9 5 8 6 7 7 6 Table A2 Algorithm trace for IsPalindromeAPPENDIX A ALGORITHM WALKTHROUGH 88 We cannot stress enough how important such traces are when designing your algorithm You can use these trace tables to verify algorithm correctness At the cost of a simple table and quick sketch of the data structure you are operatingonyoucandevisecorrectalgorithmsquicker Visualisingtheproblem domainandkeepingtrackofchangingdatamakesproblemsaloteasiertosolve Moreover you always have a point of reference which you can look back on A2 Recursive Algorithms For the most part working through recursive algorithms is as simple as walking through an iterative algorithm One of the things that we need to keep track of though is which method call returns to who Most recursive algorithms are much simple to follow when you draw out the recursive calls rather than using a table based approach In this section we will use a recursive implementation of an algorithm that computes a number from the Fiboncacci sequence 1 algorithm Fibonaccin 2 Pre n is the number in the fibonacci sequence to compute 3 Post the fibonacci sequence number n has been computed 4 if n1 5 return 0 6 else if n2 7 return 1 8 end if 9 return Fibonaccin1 Fibonaccin2 10 end Fibonacci Before we jump into showing you a diagrammtic representation of the algo rithm calls for the Fibonacci algorithm we will briefly talk about the cases of the algorithm The algorithm has three cases in total 1 n1 2 n2 3 n2 Thefirsttwoitemsinthepreceedinglistarethebasecasesofthealgorithm Until we hit one of our base cases in our recursive method call tree we wont return anything The third item from the list is our recursive case With each call to the recursive case we etch ever closer to one of our base cases FigureA2showsadiagrammticrepresentationoftherecursivecallchain In Figure A2 the order in which the methods are called are labelled Figure A3 shows the call chain annotated with the return values of each method call as well as the order in which methods return to their callers In Figure A3 the return values are represented as annotations to the red arrows It is important to note that each recursive call only ever returns to its caller upon hitting one of the two base cases When you do eventually hit a base case that branch of recursive calls ceases Upon hitting a base case you go back toAPPENDIX A ALGORITHM WALKTHROUGH 89 Figure A2 Call chain for Fibonacci algorithm Figure A3 Return chain for Fibonacci algorithmAPPENDIX A ALGORITHM WALKTHROUGH 90 the caller and continue execution of that method Execution in the caller is contiued at the next statement or expression after the recursive call was made In the Fibonacci algorithms recursive case we make two recursive calls When the first recursive call Fibonaccin1 returns to the caller we then execute the the second recursive call Fibonaccin2 After both recursive calls have returned to their caller the caller can then subesequently return to its caller and so on Recursive algorithms are much easier to demonstrate diagrammatically as Figure A2 demonstrates When you come across a recursive algorithm draw method call diagrams to understand how the algorithm works at a high level A3 Summary Understandingalgorithmscanbehardattimesparticularlyfromanimplemen tation perspective In order to understand an algorithm try and work through it using trace tables In cases where the algorithm is also recursive sketch the recursive calls out so you can visualise the callreturn chain In the vast majority of cases implementing an algorithm is simple provided that you know how the algorithm works Mastering how an algorithm works from a high level is key for devising a well designed solution to the problem in handAppendix B Translation Walkthrough The conversion from pseudo to an actual imperative language is usually very straight forward to clarify an example is provided In this example we will convert the algorithm in 91 to the C language 1 public static bool IsPrimeint number 2 3 if number 2 4 5 return false 6 7 int innerLoopBound intMathFloorMathSqrtnumber 8 for int i 1 i number i 9 10 forint j 1 j innerLoopBound j 11 12 if i j number 13 14 return false 15 16 17 18 return true 19 For the most part the conversion is a straight forward process however you may have to inject various calls to other utility algorithms to ascertain the correct result A consideration to take note of is that many algorithms have fairly strict preconditions of which there may be several in these scenarios you will need toinjectthecorrectcodetohandlesuchsituationstopreservethecorrectnessof the algorithm Most of the preconditions can be suitably handled by throwing the correct exception 91APPENDIX B TRANSLATION WALKTHROUGH 92 B1 Summary Asyoucanseefromtheexampleusedinthischapterwehavetriedtomakethe translation of our pseudo code algorithms to mainstream imperative languages as simple as possible Whenever you encounter a keyword within our pseudo code examples that you are unfamiliar with just browse to Appendix E which descirbes each key wordAppendix C Recursive Vs Iterative Solutions One of the most succinct properties of modern programming languages like C C and Java as well as many others is that these languages allow you to define methods that reference themselves such methods are said to be recursive Oneofthebiggestadvantagesrecursivemethodsbringtothetableis that they usually result in more readable and compact solutions to problems A recursive method then is one that is defined in terms of itself Generally a recursive algorithms has two main properties 1 One or more base cases and 2 A recursive case Fornowwewillbrieflycoverthesetwoaspectsofrecursivealgorithms With each recursive call we should be making progress to our base case otherwise we are going to run into trouble The trouble we speak of manifests itself typically as a stack overflow we will describe why later Now that we have briefly described what a recursive algorithm is and why you might want to use such an approach for your algorithms we will now talk about iterative solutions An iterative solution uses no recursion whatsoever An iterative solution relies only on the use of loops eg for while dowhile etc The down side to iterative algorithms is that they tend not to be as clear as to their recursive counterparts with respect to their operation The major advantage of iterative solutions is speed Most production software you will find uses little or no recursive algorithms whatsoever The latter property can sometimes be a companies prerequisite to checking in code eg upon checking in a static analysis tool may verify that the code the developer is checking in containsnorecursivealgorithms Normallyitissystemslevelcodethathasthis zero tolerance policy for recursive algorithms Using recursion should always be reserved for fast algorithms you should avoid it for the following algorithm run time deficiencies 1 On2 2 On3 93APPENDIX C RECURSIVE VS ITERATIVE SOLUTIONS 94 3 O2n Ifyouuserecursionforalgorithmswithanyoftheaboveruntimeefficiencys you are inviting trouble The growth rate of these algorithms is high and in most cases such algorithms will lean very heavily on techniques like divide and conquer While constantly splitting problems into smaller problems is good practice in these cases you are going to be spawning a lot of method calls All this overhead method calls dont come that cheap will soon pile up and either cause your algorithm to run a lot slower than expected or worse you will run out of stack space When you exceed the allotted stack space for a thread the process will be shutdown by the operating system This is the case irrespective oftheplatformyouuseeg NETornativeCetc Youcanaskforabigger stacksize butyoutypicallyonlywanttodothisifyouhaveaverygoodreason to do so C1 Activation Records An activation record is created every time you invoke a method Put simply an activation record is something that is put on the stack to support method invocation Activation records take a small amount of time to create and are pretty lightweight Normally an activation record for a method call is as follows this is very general The actual parameters of the method are pushed onto the stack The return address is pushed onto the stack The topofstack index is incremented by the total amount of memory required by the local variables within the method A jump is made to the method In many recursive algorithms operating on large data structures or algo rithms that are inefficient you will run out of stack space quickly Consider an algorithm that when invoked given a specific value it creates many recursive calls In such a case a big chunk of the stack will be consumed We will have to wait until the activation records start to be unwound after the nested methods inthecallchainexitandreturntotheirrespectivecaller Whenamethodexits its activation record is unwound Unwinding an activation record results in several steps 1 The topofstack index is decremented by the total amount of memory consumed by the method 2 The return address is popped off the stack 3 The topofstack index is decremented by the total amount of memory consumed by the actual parametersAPPENDIX C RECURSIVE VS ITERATIVE SOLUTIONS 95 While activation records are an efficient way to support method calls they can build up very quickly Recursive algorithms can exhaust the stack size allocated to the thread fairly fast given the chance Justaboutnowweshouldbedustingthecobwebsofftheageoldexampleof an iterative vs recursive solution in the form of the Fibonacci algorithm This is a famous example as it highlights both the beauty and pitfalls of a recursive algorithm The iterative solution is not as pretty nor self documenting but it does the job a lot quicker If we were to give the Fibonacci algorithm an input of say 60 then we would have to wait a while to get the value back because it has an Ogn run time The iterative version on the other hand has a On run time Dont let this put you off recursion This example is mainly used to shock programmers into thinking about the ramifications of recursion rather than warning them off C2 Some problems are recursive in nature Something that you may come across is that some data structures and algo rithms are actually recursive in nature A perfect example of this is a tree data structure A common tree node usually contains a value along with two point ers to two other nodes of the same node type As you can see tree is recursive in its makeup wit each node possibly pointing to two other nodes When using recursive algorithms on trees it makes sense as you are simply adhering to the inherent design of the data structure you are operating on Of course it is not all good news after all we are still bound by the limitations we have mentioned previously in this chapter Wecanalsolookatsortingalgorithmslikemergesort andquicksort Both of these algorithms are recursive in their design and so it makes sense to model them recursively C3 Summary Recursion is a powerful tool and one that all programmers should know of Often software projects will take a trade between readability and efficiency in which case recursion is great provided you dont go and use it to implement an algorithm with a quadratic run time or higher Of course this is not a rule of thumb this is just us throwing caution to the wind Defensive coding will always prevail Many times recursion has a natural home in recursive data structures and algorithms which are recursive in nature Using recursion in such scenarios is perfectly acceptable Using recursion for something like linked list traversal is a little overkill Its iterative counterpart is probably less lines of code than its recursive counterpart Because we can only talk about the implications of using recursion from an abstract point of view you should consult your compiler and run time environ ment for more details It may be the case that your compiler recognises things like tail recursion and can optimise them This isnt unheard of in fact most commercial compilers will do this The amount of optimisation compilers canAPPENDIX C RECURSIVE VS ITERATIVE SOLUTIONS 96 do though is somewhat limited by the fact that you are still using recursion You as the developer have to accept certain accountabilitys for performanceAppendix D Testing Testing is an essential part of software development Testing has often been discarded by many developers in the belief that the burden of proof of their software is on those within the company who hold test centric roles This couldnt be further from the truth As a developer you should at least provide a suite of unit tests that verify certain boundary conditions of your software Agreatthingabouttestingisthatyoubuildupprogressivelyasafetynet If youaddortweakalgorithmsandthenrunyoursuiteoftestsyouwillbequickly alertedtoanycasesthatyouhavebrokenwithyourrecentchanges Suchasuite oftestsinanysizeableprojectisabsolutelyessentialtomaintainingafairlyhigh bar when it comes to quality Of course in order to attain such a standard you need to think carefully about the tests that you construct Unit testing which will be the subject of the vast majority of this chapter arewidelyavailableonmostplatforms MostmodernlanguageslikeCC and Java offer an impressive catalogue of testing frameworks that you can use for unit testing The following list identifies testing frameworks which are popular JUnit Targeted at Jav httpwwwjunitorg NUnit Can be used with languages that target Microsofts Common Language Runtime httpwwwnunitorgindexphp Boost Test Library TargetedatC Thetestlibrarythatshipswiththeincrediblypopular Boostlibraries httpwwwboostorg Adirectlinktothelibrariesdoc umentationhttpwwwboostorgdoclibs1_36_0libstestdoc htmlindexhtml CppUnit Targeted at C httpcppunitsourceforgenet Dont worry if you think that the list is very sparse there are far more on offer than those that we have listed The ones listed are the testing frameworks that we believe are the most popular for C C and Java D1 What constitutes a unit test Aunittestshouldfocusonasingleatomicpropertyofthesubjectbeingtested Do not try and test many things at once this will result in a suite of somewhat 97APPENDIX D TESTING 98 unstructured tests As an example if you were wanting to write a test that verified that a particular value V is returned from a specific input I then your test should do the smallest amount of work possible to verify that V is correct given I A unit test should be simple and self describing Aswellasaunittestbeingrelativelyatomicyoushouldalsomakesurethat your unit tests execute quickly If you can imagine in the future when you may haveatestsuiteconsistingofthousandsoftestsyouwantthoseteststoexecute as quickly as possible Failure to attain such a goal will most likely result in thesuiteoftestsnotbeingranthatoftenbythedevelopersonyourteam This can occur for a number of reasons but the main one would be that it becomes incredibly tedious waiting several minutes to run tests on a developers local machine Building up a test suite can help greatly in a team scenario particularly when using a continuous build server In such a scenario you can have the suite of tests devised by the developers and testers ran as part of the build process Employingsuchstrategiescanhelpyoucatchnigglinglittleerrorcasesearly rather than via your customer base There is nothing more embarrassing for a developer than to have a very trivial bug in their code reported to them from a customer D2 When should I write my tests A source of great debate would be an understatement to personify such a ques tion as this In recent years a test driven approach to development has become very popular Such an approach is known as test driven development or more commonly the acronym TDD One of the founding principles of TDD is to write the unit test first watch it fail and then make it pass The premise being that you only ever write enoughcodeatanyonetimetosatisfythestatebasedassertionsmadeinaunit test We have found this approach to provide a more structured intent to the implementation of algorithms At any one stage you only have a single goal to makethefailingtestpass BecauseTDDmakesyouwritethetestsupfrontyou neverfindyourselfinasituationwhereyouforgetorcantbebotheredtowrite tests for your code This is often the case when you write your tests after you have coded up your implementation We as the authors of this book ourselves use TDD as our preferred method AswehavealreadymentionedthatTDDisourfavouredapproachtotesting it would be somewhat of an injustice to not list and describe the mantra that is often associate with it Red Signifies that the test has failed Green The failing test now passes Refactor Can we restructure our program so it makes more sense and easier to maintain Thefirstpointoftheabovelistalwaysoccursatleastoncemoreifyoucount the build error in TDD initially Your task at this stage is solely to make the testpassthatistomaketherespectivetestgreen ThelastitemisbasedaroundAPPENDIX D TESTING 99 the restructuring of your program to make it as readable and maintainable as possible ThelastpointisveryimportantasTDDisaprogressivemethodology to building a solution If you adhere to progressive revisions of your algorithm restructuringwhenappropriateyouwillfindthatusingTDDyoucanimplement very cleanly structured types and so on D3 How seriously should I view my test suite Your tests are a major part of your project ecosystem and so they should be treated with the same amount of respect as your production code This ranges fromcorrectandcleancodeformattingtothetestingcodebeingstoredwithin a source control repository Employing a methodology like TDD or testing after implementing you will find that you spend a great amount of time writing tests and thus they should be treated no differently to your production code All tests should be clearly named and fully documented as to their intent D4 The three As Nowthatyouhaveasenseoftheimportanceofyourtestsuiteyouwillinevitably wanttoknowhowtoactuallystructureeachblockofimperativeswithinasingle unit test A popular approach the three As is described in the following list Assemble Create the objects you require in order to perform the state based asser tions Act Invoke the respective operations on the objects you have assembled to mutate the state to that desired for your assertions Assert Specify what you expect to hold after the previous two steps The following example shows a simple test method that employs the three As public void MyTest assemble Type t new Type act tMethodA assert AssertIsTruetBoolExpr D5 The structuring of tests Structuring tests can be viewed upon as being the same as structuring pro duction code eg all unit tests for a Person type may be contained withinAPPENDIX D TESTING 100 a PersonTest type Typically all tests are abstracted from production code That is that the tests are disjoint from the production code you may have two dynamiclinklibrariesdllthefirstcontainingtheproductioncodethesecond containing your test code We can also use things like inheritance etc when defining classes of tests The point being that the test code is very much like your production code and you should apply the same amount of thought to its structure as you would do the production code D6 Code Coverage Something that you can get as a product of unit testing are code coverage statistics Codecoverageismerelyanindicatorastotheportionsofproduction codethatyourunitstestscover UsingTDDitislikelythatyourcodecoverage will be very high although it will vary depending on how easy it is to use TDD within your project D7 Summary Testing is key to the creation of a moderately stable product Moreover unit testingcanbeusedtocreateasafetyblanketwhenaddingandremovingfeatures providing an early warning for breaking changes within your production codeAppendix E Symbol Definitions Throughoutthepseudocodelistingsyouwillfindseveralsymbolsuseddescribes the meaning of each of those symbols Symbol Description Assignment Equality Less than or equal to Less than Greater than or equal to Greater than cid54 Inequality Null and Logical and or Logical or whitespace Single occurrence of whitespace yield Like return but builds a sequence Table E1 Pseudo symbol definitions This symbol has a direct translation with the vast majority of imperative counterparts 101